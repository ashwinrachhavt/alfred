{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c237c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from tinydb import TinyDB, Query\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import display, Markdown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1aca2fc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "key = os.getenv(\"LANGSEARCH_API_KEY\")\n",
    "db = TinyDB(\"search_cache.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37c74c2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"code\":200,\"log_id\":\"95087bd1eb91ecd5\",\"msg\":null,\"data\":{\"_type\":\"SearchResponse\",\"queryContext\":{\"originalQuery\":\"Tell me about the compant KnotAPI in detail\"},\"webPages\":{\"webSearchUrl\":\"https://langsearch.com/search?q=Tell me about the compant KnotAPI in detail\",\"totalEstimatedMatches\":null,\"value\":[{\"id\":\"https://api.langsearch.com/v1/#WebPages.1\",\"name\":\"KnotAPI | Adding value to your fintech clients\",\"url\":\"https://www.knotapi.com/baas/\",\"displayUrl\":\"https://www.knotapi.com/baas/\",\"snippet\":\"banking as a service \\n take your banking products to the next level \\n level up your core offerings and improve the experiences of your end users . integrate our powerful product line , from the famous...\",\"summary\":\"banking as a service \\n take your banking products to the next level \\n level up your core offerings and improve the experiences of your end users . integrate our powerful product line , from the famous card switcher to subscription manager , to outperform the competition ( without building a thing ) .\",\"datePublished\":null,\"dateLastCrawled\":null},{\"id\":\"https://api.langsearch.com/v1/#WebPages.2\",\"name\":\"API overview - KNOT SVaaS docs\",\"url\":\"https://doc.knotcity.io/svaas/api-overview/\",\"displayUrl\":\"https://doc.knotcity.io/svaas/api-overview/\",\"snippet\":\"api overview \\n knot svaas is based on an event - driven approach . in order to provide a universal solution and to avoid pooling , we based our system on two http servers communicating with each other...\",\"summary\":\"api overview \\n knot svaas is based on an event - driven approach . in order to provide a universal solution and to avoid pooling , we based our system on two http servers communicating with each other . \\n to perform an action , you have to send a request to the http api of the knot svaas server . when an event will be triggered on a product ( a station , a scooter ) , knot will make a request on the http api implemented on your server .\",\"datePublished\":null,\"dateLastCrawled\":null},{\"id\":\"https://api.langsearch.com/v1/#WebPages.3\",\"name\":\"GitHub - callmecavs/knot.js: A browser-based event emitter, for tying things together.\",\"url\":\"https://github.com/callmecavs/knot.js/\",\"displayUrl\":\"https://github.com/callmecavs/knot.js/\",\"snippet\":\"a browser - based event emitter , for tying things together . \\n code \\n knot . js \\n a browser - based event emitter , for tying things together . \\n usage \\n knot was developed with a modern javascript w...\",\"summary\":\"a browser - based event emitter , for tying things together . \\n code \\n knot . js \\n a browser - based event emitter , for tying things together . \\n usage \\n knot was developed with a modern javascript workflow in mind . to use it , it 's recommended you have a build system in place that can transpile es 6 , and bundle modules . for a minimal boilerplate that does so , check out outset . \\n follow these steps to get started : \\n install \\n call \\n then dig into the api . \\n install \\n using npm , install knot . js , and add it to your package.json dependencies . \\n $ npm install knot . js --save \\n call \\n simply import knot , then call it . \\n passed no parameters , knot will return a new emitter \\n passed an object , knot will extend it to include the emitter methods \\n note that the this context in the event handlers : \\n is the object passed in , if one was provided \\n otherwise , it is the emitter itself \\n // import knot \\n import knot from ' knot . js ' \\n // create a new emitter \\n // in the handlers , ' this ' refers to the emitter \\n const emitter = knot ( ) \\n // extend an existing object , transforming it into an emitter \\n // in the handlers , ' this ' refers to the class \\n const object = new class ( ) \\n const extended = knot ( object ) \\n api \\n all methods are chainable . \\n knot exposes the following api : \\n on \\n once \\n off \\n emit \\n . on ( name , handler ) \\n add a handler to a new or existing event . \\n // add an anonymous function as a handler \\n emitter . on ( ' name ' , ( ) = > { \\n // ... \\n } ) \\n // add a named function as a handler \\n const handler = ( ) = > { \\n // ... \\n } \\n emitter . on ( ' name ' , handler ) \\n . once ( name , handler ) \\n add a handler , that fires only once , to a new or existing event . \\n // add an anonymous function as a handler \\n emitter . once ( ' name ' , ( ) = > { \\n // ... \\n } ) \\n // add a named function as a handler \\n const handler = ( ) = > { \\n // ... \\n } \\n emitter . once ( ' name ' , handler ) \\n . off ( name [ , handler ] ) \\n remove a specific handler from an event . \\n // handler must be a named function \\n const handler = ( ) = > { \\n // ... \\n } \\n emitter . off ( ' name ' , handler ) \\n remove all of an event 's handlers . \\n emitter . off ( ' name ' ) \\n . emit ( name [ , arguments ] ) \\n emit an event , firing all of its handlers . \\n emitter . emit ( ' name ' ) \\n optionally , include arguments that will be passed to each handler . \\n // accept arguments in handler \\n emitter . on ( ' name ' , ( a , b , c , d ) = > console . log ( a , b , c , d ) ) \\n // include arguments in call to emit \\n emitter . emit ( ' name ' , 1, ' 2 ' , [ 3 ] , { } ) \\n // log : 1 ' 2 ' [ 3 ] { } \\n browser support \\n tested in all modern browsers and ie 10 + . \\n license \\n mit . © 2017 michael cavalea \\n event emitter\",\"datePublished\":null,\"dateLastCrawled\":null},{\"id\":\"https://api.langsearch.com/v1/#WebPages.4\",\"name\":\"MongoDB Blog\",\"url\":\"https://www.mongodb.com/company/blog/channel/home/7\",\"displayUrl\":\"https://www.mongodb.com/company/blog/channel/home/7\",\"snippet\":\"mongodb blog \\n announcements , updates , news , and more \\n mongodb.local nyc 2025 : defining the ideal database for the ai era \\n home \\n cars24 improves search for 300 million users with mongodb atlas ...\",\"summary\":\"mongodb blog \\n announcements , updates , news , and more \\n mongodb.local nyc 2025 : defining the ideal database for the ai era \\n home \\n cars24 improves search for 300 million users with mongodb atlas \\n the indian multinational online car marketplace cars24 serves 300 million users globally . the company offers services that span sales , insurance , maintenance , financing , and more , reshaping the entire car ownership journey . speaking at mongodb .local bengaluru in july 2025 , pradeep sharma , head of technology at cars 24 , shared how mongodb has been a key driver of car24 ’s digital transformation journey . specifically , he highlighted two recent use cases that show how mongodb atlas has helped cars24 scale , improve its search capabilities , and reduce its architectural complexity . matching the growing scale with simplified and expanded search cars24 has operations in multiple countries , and a diverse customer base . over the years , the company has used customer data , behavior analytics , and operational workflows to build , evolving from being a platform for buying and selling cars , to an end - to - end ecosystem , supported by a hub of interconnected systems . at the start of its journey , cars24 relied on legacy databases for managing and searching data , such as postgres . their relational database set - up would store information , synchronize the data to a separate “ bolt - on ” search engine ( such as elasticsearch ) , manually indexing it , and then querying the index . while initially effective for a small application ecosystem , these processes became bottlenecked as the organization ’s services grew . multiple engineering teams piped data into a single search index , which often resulted in synchronization challenges and overwhelming administrative overhead . cars24 faced three core limitations with this setup : lower developer productivity : exponential effort was spent maintaining pipelines and synchronizing procedures . developers had little bandwidth for building business features or innovation . architectural complexity : ensuring data sync consistency required multiple pipelines and race logic . this led to inefficiencies in real - time dashboard updates for agents . operational overhead : maintaining separate systems for database and search — alongside provisioning , patching , scaling , and monitoring — strained resources . seeking an integrated approach , cars24 embraced mongodb atlas , hosted on google cloud . mongodb atlas would serve as a single , consistent , modern database and embedded search solution , powered by apache lucene . mongodb atlas search also enabled cars24 to run queries directly in the database . this eliminated the need to synchronise data between systems while delivering real - time results . this unified approach allowed the company ’s developers to transition from managing complex synchronization mechanisms to building applications . furthermore , the reduced administrative overhead enabled cars24 to consolidate the team ’s efforts , and to streamline query execution across the ecosystem . thanks to mongodb atlas and mongodb atlas search , cars24 was able to : avoid \\\" synchronization tax ” : switching to mongodb atlas eliminated the need for data synchronization and the additional tooling this mandated . real - time searches can be performed from a single interface and workflow . deliver new search features faster : by using a single , unified api across database and search operations , new features can be delivered rapidly . work with a fully managed platform : with mongodb atlas , cars24 ’s engineers can focus more on application development and building products , rather than thinking about managing indexes , syncing , and more . following this successful migration , cars24 decided to also use mongodb atlas to replace one of its legacy databases , arangodb . the switch to mongodb atlas eliminated major roadblocks for other critical search capabilities . from arangodb to mongodb : streamlined operations and 50 % cost savings as cars24 scaled new services globally , it encountered limitations with its geospatial search solution , which was based on arangodb . this included performance bottlenecks , weak transactions as it was difficult to guarantee consistent data operations , and a limited ecosystem which meant that scaling developer onboarding and troubleshooting became increasingly onerous . moving to mongodb atlas enabled cars24 to transition its geospatial services , consolidating its data storage and search capabilities under a single , versatile platform . “ we now have a highly available architecture , and an amazing team at mongodb that has our back , ” said sharma . mongodb offered a proven architecture for high availability , scalability , and real - world production readiness : enhanced scalability : mongodb ’s ability to scale massive workloads supports cars24 ’s growing global presence . reliable transactions : mongodb provides robust multi - document acid transactions across shards , meeting mission - critical needs . streamlined operations : mongodb offers a single platform that is not limited to a database only . by consolidating its geospatial search workload under mongodb , cars24 has reduced maintenance and operational overhead . not only did cars24 cut costs in half by moving to mongodb , but the widespread market adoption of mongodb atlas also means that cars24 can continue to rapidly onboard developers familiar with mongodb , a recruiting priority for cars24 ’s growing development team . “ to give you an idea , one of our business units had a developer team of less than 10 about a year ago . now they are a triple - digit team , ” said sharma . “ if we are going to keep introducing new developers , for a product coming up or scaling up , it becomes very important to focus on the community skills and support provided by our technology partner . ” “ now that we have moved from arangodb to mongodb atlas , our developers are the happiest , ” he added . cars24 is now looking to consolidate even more of its application and data workflows under mongodb atlas . with the growing number of developers joining cars24 ’s engineering teams , plans are to utilize mongodb atlas further to enhance productivity , scalability , and data - driven insights . visit the mongodb atlas learning hub to learn more about atlas . to learn more about mongodb atlas search , visit our product page . \\n home \\n innovating with mongodb | customer successes , october 2025 \\n it ’s officially fall ! the start of every new season is a perfect time to consider change and new beginnings . while fall might make you think about pumpkin spice and newly chilly evenings , i ’m thinking about the latest round of transformations that mongodb ’s customers are embracing to thrive in an ai - powered world . in all seriousness , legacy systems and technical debt are huge challenges : the cost of tech debt has been estimated at almost $ 4 trillion dollars . that ’s trillion with a t ! legacy systems can slow down innovation , create bottlenecks , and make it tough to deliver the seamless , real - time experiences customers increasingly expect . but companies are finding that modernizing their applications isn't just about fixing what 's broken — modernization enables them to move faster and innovate for end - users . that ’s why i 'm incredibly excited to share the recent launch of mongodb ’s application modernization platform ( amp ) . this ai - powered program is designed to help enterprises move beyond outdated infrastructures to embrace a flexible , data - driven future . amp is a comprehensive approach to modernization that combines smart ai tooling with proven methodologies , enabling businesses to transform their applications from the ground up , moving from legacy monoliths to a more flexible , microservices - based architecture . in this roundup , we 're spotlighting customers who understand the strategic importance of modernization . you'll see how wells fargo is using mongodb to power a new credit card platform , how csx is ensuring business continuity during a critical migration , how intellect design is modernizing its wealth management platform , and how deutsche telekom is transforming its b2c digital channels . with mongodb , customers are showing how integral a modern database is to powering the next generation of applications — and succeeding in the ai era . wells fargo wells fargo sought to modernize its mainframe - dependent credit card platform to provide a faster , more seamless customer experience and handle an exponential increase in transaction data . the company 's legacy system was costly to manage and lacked the scalability needed for its \\\" cards 2 . 0 \\\" initiative . to solve this , wells fargo built an operational data store ( ods ) using mongodb . this new platform allowed them to adopt reusable apis , streamline integrations , and move from a monolithic architecture to flexible microservices . the ods now serves 40 % of traffic from external vendors , handling more than 7 million transactions with sub - second service . by leveraging mongodb , wells fargo was able to jumpstart its mainframe modernization and create curated data products to serve real - time , personalized financial services . csx csx , a major u.s. railroad company , sought to modernize its critical operations platform , r top , by migrating it to the cloud . the challenge was to maintain the platform 's 24/7 availability with minimal disruption to its mission - critical , near real - time operations during the transition . to solve this , csx selected mongodb atlas on azure and partnered with mongodb professional services . leveraging the cluster - to - cluster sync feature , the team was able to facilitate continuous data synchronization and complete the entire migration in just a few hours . the move to mongodb atlas has equipped csx with a more scalable and resilient platform . this modernization effort established a blueprint for migrating other critical applications and helped csx continue its digital transformation journey toward becoming america ’s best - run railroad . intellect design intellect design , a global fintech company , sought to modernize its wealth management platform to overcome legacy system bottlenecks and multi hour batch processing delays . the company 's rigid relational database architecture limited its ability to scale and innovate . to solve this , the company partnered with mongodb , using our amp methodology and generative ai tools . this transformation reengineered the platform 's core components , resulting in an 85 % reduction in onboarding workflow times , allowing clients to access critical portfolio insights faster than ever . this initiative is the first step in intellect design 's long - term vision to integrate its entire application suite into a unified , ai - driven service . by leveraging mongodb atlas 's flexible schema and powerful native tools , the company is now better positioned to deliver smarter analytics and advanced ai capabilities to its customers . watch intellect ai ’s mongodb.local bengaluru keynote presentation to learn how amp helped them transform outdated systems into scalable , modern solutions . deutsche telekom deutsche telekom , a leading telecommunications company , sought to modernize its b2c digital channels , which were fragmented by outdated legacy systems . the company needed to create a unified digital experience for its 30 million customers while improving developer productivity . by leveraging mongodb atlas as part of its internal developer platform , deutsche telekom built a robust data infrastructure to unify customer data and power its new digital services . this approach allowed the company to retire legacy systems and reduce its reliance on physical shops and call centers . the transition to mongodb atlas led to a massive surge in digital engagement , with daily customer interactions rising from under 50,000 to approximately 1.5 million . the company 's customer data platform now handles up to 15 times the load of legacy systems , supporting large - scale loyalty programs and transforming the customer experience . video spotlight : bendigo bank before you go , watch how bendigo and adelaide bank modernized their core banking technology using mongodb atlas and generative ai . bendigo and adelaide bank reduced the migration time for legacy applications from 80 hours to just five minutes . this innovative approach allowed them to quickly modernize their systems and better serve their 2.5 million customers . want to get inspired by your peers and discover all the ways we empower businesses to innovate for the future ? visit mongodb ’s customer success stories hub to see why these customers , and so many more , build modern applications with mongodb . \\n home \\n the 10 skills i was missing as a mongodb user \\n when i first started using mongodb , i didn’t have a plan beyond “ install it and hope for the best . ” i had read about how flexible it was , and it felt like all the developers swore by it , so i figured i ’d give it a shot . i spun it up , built my first application , and got a feature working . but i felt like something was missing . it felt clunky . my queries were longer than i expected , and performance wasn’t great ; i had the sense that i was fighting with the database instead of working with it . after a few projects like that , i began to wonder if maybe mongodb wasn’t for me . looking back now , i can say the problem wasn’t mongodb , but was somewhere between the keyboard and the chair . it was me . i was carrying over habits from years of working with relational databases , expecting the same rules to apply . if mongodb ’s skill badges had existed when i started , i think my learning curve would have been a lot shorter . i had to learn many lessons the hard way , but these new badges cover the skills i had to piece together slowly . instead of pretending i nailed it from day one , here ’s the honest version of how i learned mongodb , what tripped me up along the way , and how these skill badges would have helped . learning to model the mongodb way the first thing i got wrong was data modeling . i built my schema like i was still working in sql– every entity in its own collection , always referencing instead of embedding , and absolutely no data duplication . it felt safe because it was familiar . then i hit my first complex query . it required data from various collections , and suddenly , i found myself writing a series of queries and stitching them together in my code . it worked , but it was a messy process . when i discovered embedding , it felt like i had found a cheat code . i could put related data together in one single document , query it in one shot , and get better performance . that ’s when i made my second mistake . i started embedding everything . at first , it seemed fine . however , my documents grew huge , updates became slower , and i was duplicating data in ways that created consistency issues . that ’s when i learned about patterns like extended references , and more generally , how to choose between embedding and referencing based on access patterns and update frequency . later , i ran into more specialized needs , such as pre - computing data , embedding a subset of a large dataset into a parent , and tackling schema versioning . back then , i learned those patterns by trial and error . now , they ’re covered in badges like relational to document model , schema design patterns , and advanced schema patterns . fixing what i thought was “ just a slow query ” even after i got better at modeling , performance issues kept popping up . one collection in particular started slowing down as it grew , and i thought , “ i know what to do ! i ’ll just add some indexes . ” i added them everywhere i thought they might help . nothing improved . it turns out indexes only help if they match your query patterns . the order of fields matters , and whether you cover your query shapes will affect performance . most importantly , just because you can add an index doesn’t mean that you should be adding it in the first place . the big shift for me was learning to read an explain ( ) plan and see how mongodb was actually executing my queries . once i started matching my indexes to my queries , performance went from “ ok ” to “ blazing fast . ” around the same time , i stopped doing all my data transformation in application code . before , i ’d pull in raw data and loop through it to filter , group , and calculate . it was slow , verbose , and easy to break . learning the aggregation framework completely changed that . i could handle the filtering and grouping right in the database , which made my code cleaner and the queries faster . there was a lot of guesswork in how i created my indexes , but the new indexing design fundamentals covers that now . and when it comes to querying and analyzing data , fundamentals of data transformation is there to help you . had i had those two skills when i first started , i would ’ ve saved a lot of time wasted on trial and error . moving from “ it works ” to “ it works reliably ” early on , my approach to monitoring was simple : wait for something to break , then figure out why . if a performance went down , i ’d poke around in logs . if a server stopped responding , i ’d turn it off and on again , and hope for the best . it was stressful , and it meant i was always reacting instead of preventing problems . when i learned to use mongodb ’s monitoring tools properly , that changed . i could track latency , replication lag , and memory usage . i set alerts for unusual query patterns . i started seeing small problems before they turned into outages . performance troubleshooting became more methodical as well . instead of guessing , i measured . breaking down queries , checking index use , and looking at server metrics side by side . the fixes were faster and more precise . reliability was the last piece i got serious about . i used to think a working cluster was a reliable cluster . but reliability also means knowing what happens if a node fails , how quickly failover kicks in , and whether your recovery plan actually works in practice . those things you can now learn in the monitoring tooling , performance tools and techniques , and cluster reliability skill badges . if you are looking at deploying and maintaining mongodb clusters , these skills will teach you what you need to know to make your deployment more resilient . getting curious about what ’s next once my clusters were stable , i stopped firefighting , and my mindset changed . when you trust your data model , your indexes , your aggregations , and your operations , you get to relax . you can then spend that time on what ’s coming next instead of fixing what ’s already in production . for me , that means exploring features i wouldn’t have touched earlier , like atlas search , gen ai , and vector search . now that the fundamentals are solid , i can experiment without risking stability and bring in new capabilities when a project actually calls for them . what i ’d tell my past self if i could go back to when i first installed mongodb , i ’d keep it simple : focus on data modeling first . a good foundation will save you from most of the problems i ran into . once you have that , learn indexing and aggregation pipelines . they will make your life much easier when querying . start monitoring from day one . it will save you a lot of trouble in the long run . take a moment to educate yourself . you can only learn so much from trial and error . mongodb offers a myriad of resources and ways to upskill yourself . once you have established that base , you can explore more advanced topics and uncover the full potential of mongodb . features like vector search , full - text search with atlas search , or advanced schema design patterns are much easier to adopt when you trust your data model and have confidence in your operational setup . mongodb skill badges cover all of these areas and more . they are short , practical , and focused on solving real problems you will face as a developer or dba , and most of them can be taken over your lunch break . you can browse the full catalog at learn . mongodb . com / skills and pick the one that matches the challenge you are facing today . keep going from there , and you might be surprised how much more you can get out of the database once you have the right skills in place . \\n developer blog \\n smarter ai search , powered by mongodb atlas and pureinsights \\n we ’re excited to announce that the integration of mongodb atlas with the pureinsights discovery platform is now generally available — bringing to life a reimagined search experience powered by keyword , vector , and gen ai . what if your search box didn’t just find results , but instead understood intent ? that ’s exactly what this integration delivers ! beyond search : from matching to meaning developers rely on mongodb ’s expansive knowledge ecosystem to find answers fast . but even with a rich library of technical blogs , forum threads , and documentation , traditional keyword search often falls short — especially when queries are nuanced , multilingual , or context - driven . that ’s where the mongodb - pureinsights solution shines . built on mongodb atlas and orchestrated by the pureinsights discovery platform , this intelligent search experience starts with the fundamentals : fast , accurate keyword results , powered by mongodb atlas search . but as queries grow more ambiguous — say , “ tutorials for ai ” — the platform steps up . mongodb atlas vector search with voyage ai , available as an embedding and reranking option ( now part of mongodb ) , goes beyond literal keywords to interpret intent — helping applications deliver smarter , more relevant results . the outcome : smarter , semantically aware responses that feel intuitive and accurate — because they are . what ’s more , with generative answers enabled , the platform synthesizes information across mongodb ’s ecosystem ( blog content , forums , and technical docs ) to deliver clear , contextual answers using state - of - the - art language models . but it 's not just pointing you to the right page . instead , the platform is providing the right answer , with citations , ready to use . it ’s like embedding a domain - trained ai assistant directly into your search bar . “ as organizations look to move beyond traditional keyword search , they need solutions that combine speed , relevance , and contextual understanding , ” said haim ribbi , vice president , global csi , var & tech partner at mongodb . “ mongodb atlas provides the foundation for smarter discovery , and this collaboration with pureinsights shows how easily teams can deliver gen ai - powered search experiences using their existing content . ” built for users everywhere but intelligence alone doesn’t make it transformational . what sets this experience apart is its adaptability . whether you ’re a developer troubleshooting in berlin or a product owner building in são paulo , the platform tailors responses to your preferences . prefer concise summaries or deep technical dives ? want to translate answers in real time ? need responses that reflect your role and context ? you ’re in control . from tone and length to language and specificity , this is a search that truly understands you — literally and figuratively . built on mongodb . elevated by voyage ai . delivered by pureinsights . at the core of this solution is mongodb atlas , which unifies fast , scalable data access to structured content through atlas search and atlas vector search . looking ahead , by integrating with voyage ai ’s industry - leading embedding models , mongodb atlas aims to make semantic search and retrieval - augmented generation ( rag ) applications even more accurate and reliable . while currently in private preview , this enhancement signals a promising future for developers building intelligent , ai - powered experiences . pureinsights handles the orchestration layer . their discovery platform ingests and enriches content , blends keyword , vector , and generative search into a seamless ui , and integrates with large language models like gpt - 4 . the platform supports multilingual capabilities , easy deployment , and enterprise - grade scalability out of the box . while generative answers are powered by integrated large language models ( llms ) and may vary by deployment , the solution is enterprise - ready , cloud - native , and built to scale . bringing intelligent discovery to your own data watch the demo video to see ai - powered search in action across 4 , 000 + pages of mongodb content — from community forums and blog posts to technical documentation . while the demo features mongodb ’s content , the solution is built to adapt . you can bring the same ai - powered experience to your internal knowledge base , customer support portal , or developer hub — no need to build from scratch . visit our partner page to learn more about mongodb and pureinsights and how we ’re helping enterprises build smarter , ai - powered search experiences . apply for a free gen ai demo using your enterprise content . \\n artificial intelligence \\n charting a new course for saas security : why mongodb helped build the sscf \\n the way companies everywhere work is powered by saas . from collaboration tools to critical infrastructure , organizations rely on saas applications to drive their business forward . but this widespread adoption has created a significant security blind spot . how can you ensure every one of these applications is configured securely when they all offer different settings , capabilities , and levels of visibility ? this inconsistency creates friction , wastes resources , and ultimately , exposes businesses to unnecessary risk . at mongodb , we believe that securing the saas ecosystem is a shared responsibility . that 's why we were proud to collaborate with the cloud security alliance ( csa ) and industry leaders like guidepoint security to develop a new standard — the saas security capability framework ( sscf ) . the problem : a gap in cloud security for years , the majority of security assessments have focused on the saas provider 's organizational security , often through frameworks like soc 2 or iso 27001 . while essential , these frameworks don't always address a critical question : what security capabilities are available to the saas customer within the application ? this gap means that security teams face a chaotic landscape . every new saas app brings a different set of configurable controls for logging , identity management , and data access . this makes it nearly impossible to implement and track consistent security policies at scale , leading to a burdensome assessment process for everyone involved . the solution : a common framework for saas security the sscf was created to solve this problem by establishing a clear , technical set of customer - facing security controls that saas vendors should provide . the framework is designed to empower customers by ensuring they have the tools they need to operate applications securely at scale on their side of the shared security responsibility model ( ssrm ) . the framework helps with many use cases , but three key audiences stand out : for risk management teams : the sscf provides a clear baseline to use during vendor assessments , simplifying procurement . for saas security teams : it offers a checklist for implementing the security features enterprises expect , streamlining the security program . for saas vendors : the sscf standardizes assessment responses , reducing the overhead of custom questionnaires and helping vendors meet customer requirements . the sscf focuses on six critical domains , aligned with csa ’s cloud control matrix , providing specific and actionable controls for each : change control and configuration management ( ccc ) : ensuring you can programmatically query and get documentation on all security configurations . data security and privacy life cycle management ( dsp ) : giving customers control over features like disabling file uploads to prevent malicious code . identity and access management ( iam ) : providing robust , modern controls for user access , including sso enforcement , non - human identity ( nhi ) governance , and a dedicated read - only security auditor role . interoperability and portability ( ipy ) : giving administrators control over mass data exports and visibility into application integrations . logging and monitoring ( log ) : defining a clear set of comprehensive requirements for machine - readable logs with mandatory fields for effective threat detection and forensics . security incident management ( sef ) : requiring a simple , effective way for vendors to notify a designated customer security contact during an incident . mongodb 's commitment to a more secure ecosystem our involvement in creating the sscf stems from our deep commitment to the security of our customers ' data and the broader developer community . we believe that robust security shouldn't be an afterthought ; it must be built in and easy to consume . the principles outlined in the sscf — like strong identity controls and comprehensive logging — are philosophies we already built into our own data platform . strong security capabilities allow our customers to build and innovate faster and more securely , knowing they have a reliable foundation . and personally , as a co - chair of the csa sscf , i ’ve seen great excitement and engagement on the part of our working group—which helped me realize how many companies are affected by this lack of consistency . the sscf is a vital step toward creating a more trusted , efficient , and secure global saas ecosystem . we are thrilled to have been a part of this foundational work and will continue to champion this standard that empowers developers and security teams alike . visit our security page to learn more about how mongodb helps protect your data . \\n home \\n from niche nosql to enterprise powerhouse : the story of mongodb 's evolution \\n i joined mongodb two years ago through the acquisition of grainite , a database startup i co - founded . my journey here is built on a long career in databases , including many years at google , where i was most recently responsible for the company ’s entire suite of native databases — big table , spanner , datastore , and firestore — powering both google 's own products and google cloud customers . my passion has always been large - scale distributed systems , and i find that the database space offers the most exciting and complex challenges to solve . at mongodb my focus is on architectural improvements across the product stack . i 've been impressed with the progression of mongodb 's capabilities and the team 's continuous innovation ethos . in this blog post , i ’ll share some of my understanding of mongodb ’s history and how mongodb became the de facto standard for document databases . i ’ll also highlight select innovations we are actively exploring . the dawn of nosql during the \\\" move fast and break things \\\" era of web 2 . 0 , the digital landscape was exploding . developers were building dynamic , data - rich applications at an unprecedented pace , and the rigid , tabular structures of legacy relational databases like oracle and microsoft sql server quickly became a bottleneck . a new approach was needed , one that prioritized developer productivity , flexibility , and massive scale . at the same time , json 's popularity as a flexible , cross - language format for communicating between browsers and backends was surging . this collective shift toward flexibility gave rise to nosql databases , and mongodb , with its native document - based approach , was at the forefront of the movement . in the early days , there was a perception that mongodb was great for use cases like social media feeds or product catalogs , but not for enterprise applications where data integrity is non - negotiable — like financial transactions . this view was never perfectly accurate , and it certainly isn't today . so , what created this perception ? it came down to two main factors : categorization and maturity . first , most early nosql databases were built on an “ eventually consistent ” model , prioritizing availability and partition tolerance ( ap ) under the cap theorem . mongodb was an exception , designed to prioritize consistency and partition tolerance ( cp ) . but , in a market dominated by ap systems , mongodb was often lumped in with the rest , leading to the imprecise label of having “ light consistency . ” second , all new databases take time to mature for mission - critical workloads . any established system - of - record database today has gone through many versions over many years to earn that trust . after more than 15 years of focused engineering , today mongodb has the required codebase maturity , features , and proven track record for the most demanding enterprise applications . the results speak for themselves . as our ceo dev ittycheria mentioned during the q2 2026 earnings call , over 70 % of the fortune 500 — as well as 7 of the 10 largest banks , 14 of the 15 largest healthcare companies , and 9 of the 10 largest manufacturers globally — are mongodb customers . this widespread adoption by the world 's most sophisticated organizations is a testament to a multi - year , deliberate engineering journey that has systematically addressed the core requirements of enterprise - grade systems . mongodb ’s engineering journey : building a foundation of trust mongodb ’s evolution from being perceived as a niche database to an enterprise powerhouse wasn't an accident ; it was the result of a relentless focus on addressing the core requirements of enterprise - grade systems . improvements instrumental to this transformation include : high availability with replica sets : the first step was eliminating single points of failure . replica sets were introduced as self - healing clusters that provide automatic failover , ensuring constant uptime and data redundancy . later , the introduction of a raft - style consensus protocol provided even more reliable and faster failover and leader elections , especially in the event of a network partition . this architecture is the foundation for mongodb ’s current multi - region or run - anywhere deployments , and even allows a single replica set to span multiple cloud providers for maximum resilience . figure 1. horizontal scaling . massive scalability with horizontal sharding : introduced at the same time as replica sets , sharding is a native , foundational part of mongodb . mongodb built sharding to allow data to be partitioned across multiple servers , enabling virtually limitless horizontal scaling to support massive datasets and high - throughput operations . advanced features like zone sharding further empower global applications by pinning data to specific geographic locations to reduce latency and comply with data residency laws like gdpr . tunable consistency : recognizing that not all data is created equal , mongodb empowered developers with tunable read and write concerns . within a single application , some data — like a ' page view count ' — might not have the same consistency requirements as a ' order checkout value ' . instead of using separate , specialized databases for each use case , developers can use mongodb for both . this moved the platform beyond a one - size - fits - all model , allowing teams to choose the precise level of consistency their application required per operation — from \\\" fire and forget \\\" for speed to fully acknowledged writes across a majority of replicas for guaranteed durability . this flexibility provides the best price / performance tradeoffs for modern applications . the game - changer , multi - document acid transactions : from its inception , mongodb has always provided atomic operations for single documents . the game - changing moment was the introduction of multi - document acid transactions in 2018 with mongodb 4 . 0 , which was arguably the single most important development in its history . this feature , later extended to include sharded clusters , meant that complex operations involving multiple documents — like a financial transfer between two accounts — could be executed with the same atomicity , consistency , isolation , and durability ( acid ) guarantees as a traditional relational database . this milestone shattered the biggest barrier to adoption for transactional applications . and the recently released mongodb 8.2 is the most feature - rich and performant version of mongodb yet . strict security and compliance : to meet the stringent security demands of the enterprise , mongodb layered in a suite of advanced security controls . features like role - based access control ( rbac ) , detailed auditing , and field - level encryption were just the beginning . the release of queryable encryption ( to which we recently introduced support for prefix , suffix , and substring queries ) marked a revolutionary breakthrough , allowing non - deterministic encrypted data to be queried without ever decrypting it on the server , ensuring data remains confidential even from the database administrator . to provide independent validation , mongodb atlas has achieved a number of internationally recognized security certifications and attestations , including iso/iec 27001 , soc 2 type ii , pci dss , and hipaa compliance , demonstrating a commitment to meeting the rigorous standards of the world 's most regulated industries . figure 2. queryable encryption . the ultimate proof of enterprise readiness lies in real - world adoption . today , mongodb is trusted by leading organizations across the most demanding sectors to run their core business systems . for example , citizens bank , one of the oldest and largest financial institutions in the united states , moved to modernize its fraud detection capabilities from a slow , batch - oriented legacy system . they built a new , comprehensive fraud management platform on mongodb atlas that allows for near real - time monitoring of transactions . this use case in a highly regulated industry requires high availability , low latency , and strong consistency to analyze transactions in real - time and prevent financial loss — a direct refutation of the old \\\" eventual consistency \\\" criticism . another example is that of bosch digital , the software and systems house for the bosch group . bosch digital uses mongodb for its iot platform , bosch iot insights , to manage and analyze massive volumes of data from connected devices — from power tools used in aircraft manufacturing , to sensors in vehicles . iot data arrives at high speeds , in huge volumes , and in variable structures . this mission - critical use case demonstrates mongodb 's ability to handle the demands of industrial - scale iot , providing the real - time analytics needed to ensure quality , prevent errors , and drive innovation . then there ’s coinbase , which relies on mongodb to seamlessly handle the volatile and unpredictable cryptocurrency market . specifically , coinbase architected a mongodb atlas solution that would accelerate scaling for large clusters . the result was that coinbase end - users gained a more seamless experience . previously , traffic spikes could impact some parts of the coinbase app . now , users don’t even notice changes happening behind the scenes . these are just a few examples ; customers across all verticals , industries , and sizes depend on mongodb for their most demanding production use cases . a common theme is that real - world data is messy , variable , and doesn't fit neatly into rigid , tabular structures . the old adage says that if all you have is a hammer , everything looks like a nail . for decades , developers only had the relational \\\" hammer . \\\" with mongodb , they now have a modern tool that adapts to how developers work and the data they need to manage and process . the road ahead : continuous innovation mongodb is not resting on its laurels . the team is as excited about what the future holds as they were when mongodb was first launched , and we continue to innovate aggressively to meet — and anticipate — the modern enterprise ’s demands . here are select improvements we are actively exploring . a critical need we hear from customers is how to support elastic workloads in a price - performant way . to address this , over the past two years we’ve rolled out search nodes , which is a unique capability in mongodb that allows scaling of search and vector workloads independent from the database to improve availability and price performance . we are now working closely with our most sophisticated customers to explore how to deliver similar capabilities across more of mongodb . our vision is to enable customers to scale compute for high - throughput queries without over - provisioning storage , and vice versa . we can do all this while building upon what is already one of the strongest security postures of any cloud database , as we continue to raise the bar for durability , availability , and performance . another challenge facing large enterprises is the significant cost and risk associated with modernizing legacy applications . to solve this , we are making a major strategic investment in enterprise application modernization , and recently announced the mongodb application modernization platform . we have been engaged with several large enterprises in migrating their legacy relational database applications — code , data , and everything in between — over to mongodb . this is not a traditional , manual migration effort capped by the number of bodies assigned . instead , we are systematically developing agentic tooling and ai - based frameworks , techniques , and processes that allow us to smartly migrate legacy applications into modern microservices - based architectures at scale . one of the more exciting findings from a recent effort , working with a large enterprise in the insurance sector , was that optimized queries on mongodb ran just as fast , and often significantly faster , than on their legacy relational database , even when schemas were translated 1:1 between relational tables and mongodb collections , and lots of nested queries and joins were involved . batch jobs implemented as complex stored procedures that took several hours to execute on the relational database could be completed in under five minutes , thanks to the parallelism mongodb natively enables ( for more , see the mongodb developer blog ) . based on the incredible performance gains seen in these modernization projects , we 're addressing another common need : ensuring fast queries even when data models aren't perfectly optimized . we are actively exploring improvements to our query optimizer that will improve lookup and join performance . while the document model will always be the most performant way to model your data , we are ensuring that even when you don't create the ideal denormalized data model , mongodb will deliver performance that is at par or better than the alternatives . finally , developers today are often burdened with stitching together multiple services to build modern , ai - powered applications . to simplify this , the platform is expanding far beyond a traditional database , focused on providing a unified developer experience . this includes a richer ecosystem with integrated capabilities like atlas search for full - text search , atlas vector search for ai - powered semantic search , and native stream processing to handle real - time data . we are already working on our first integrations , and continue to explore how embedding generation as a service within mongodb atlas , powered by our own voyage ai models , can further simplify application development . from niche to necessity mongodb began its journey as a ( seemingly ) niche nosql database with perceptions and tradeoffs that made it unsuitable for many core business applications . but , through a sustained and deliberate engineering effort , it has delivered the high availability , tunable consistency , acid transactions , and robust security that enterprises demand . the perceptions of the past no longer match the reality of the present . when 7 of the 10 largest banks are already using mongodb , isn’t it time to re - evaluate mongodb for your most critical applications ? for more on why innovation requires a modern , ai - ready database — and why companies like nationwide , wells fargo , and the knot worldwide chose mongodb over relational data bases— see the mongodb customer use case site . \\n home \\n mongodb sql interface : now available for enterprise advanced \\n today , we ’re excited to announce the general availability of mongodb sql interface for mongodb enterprise advanced . this builds upon the foundation established by mongodb atlas sql interface , which began by extending sql connectivity to self - managed mongodb deployments . teams can now query their mongodb data directly from familiar bi tools like tableau and microsoft ’s power bi using standard odbc and java database connectivity ( jdbc ) connections , eliminating the need to learn mongodb query language ( mql ) , build extract , transform , and load ( etl ) pipelines , or move data . bridging the sql - mongodb gap organizations new to mongodb often face a data access challenge : while developers benefit from increased flexibility and performance , teams moving from sql - based tools often struggle to access the data they need . without direct sql connectivity , they must either learn mongodb ’s query language or build and maintain custom etl pipelines to move data out of mongodb for reporting and analytics . this creates fragmented operational reporting workflows , with users switching between multiple tools and data sources to piece together the insights they need . these approaches often lead to increased maintenance overhead , outdated data , and dependency bottlenecks . mongodb sql interface now eliminates this friction by providing direct sql access to mongodb data through custom connectors and drivers . this works by generating comprehensive json schemas of mongodb collections and translating standard sql queries into mongodb operations in real time . users can connect from popular bi tools like tableau and power bi , or through jdbc and odbc drivers for other sql - based tools . they can use familiar sql syntax , including joins , aggregations , and subqueries through mongosql , a sql-92 compatible dialect designed specifically for mongodb . this speeds up analysis and enables self-service reporting while maintaining database performance . getting started mongodb sql interface is now included with enterprise advanced licenses and works with mongodb 6.0 or higher , requiring no changes to your existing mongodb server configuration . the set up process involves three main steps : download the mongodb sql schema builder cli from the download center . use the command line interface ( cli ) to analyze your data structure and generate schemas that map your collections ’ document structures to sql - queryable formats . connect your bi tools using mongodb ’s custom connectors for tableau and power bi , or jdbc and odbc drivers for other sql - based tools . the schema builder cli examines your existing collections to understand document patterns , nested objects , and array structures . it then creates json schema definitions that preserve the full richness of your document model while making complex nested structures and arrays queryable through familiar sql syntax . this schema - first approach ensures optimal query performance and maintains data type accuracy across your sql operations . once the mongodb schema builder cli generates your schemas , it stores them alongside your data . sql interface then automatically uses them to validate queries and provide proper type information for results . this creates a seamless bridge between mongodb ’s flexible document model and sql ’s structured query expectations . moving forward from mongodb bi connector for organizations currently using mongodb bi connector , mongodb sql interface represents a significant improvement to our sql connectivity solution . the interface addresses several limitations of the mongodb bi connector approach , including improved query performance through native mongodb operations and enhanced schema flexibility that better represents document structures . while support for bi connector will continue until september 2026 , mongodb sql interface offers improved performance , enhanced schema control , and a more intuitive set up process . ready to get started with mongodb sql interface for enterprise advanced ? documentation : complete the implementation guide with configuration options and best practices . download center : get the mongodb sql schema builder cli and drivers for your deployment . readme : use this guide for quick reference for installation and usage . demo video : see mongodb sql interface in action with a step - by - step walkthrough . \\n home \\n mongodb is a glassdoor best - led company of 2025 \\n 2025 has been a big year for mongodb . with mongodb 8 . 2 , our most feature - rich and performant release yet , we are raising the bar for what developers can achieve . voyage ai ’s embedding models and rerankers are bringing state - of - the - art accuracy and efficiency to building trustworthy , reliable ai applications . and we’ve launched the mongodb application modernization platform , or amp . today , mongodb serves nearly 60,000 organizations across every industry and vertical , including more than 70 % of the fortune 500 and cutting - edge ai - native startups . on top of these exciting updates , we ’re now pleased to announce that mongodb is among the winners of the annual glassdoor list of best - led companies in 2025 . this list highlights the top 50 companies with more than 1,000 employees whose leaders have been recognized as some of the best . for us , this is not just an external badge of honor—it ’s a reflection of the trust and inspiration that mongodb employees experience every day . what makes this award so meaningful is that it ’s driven entirely by employee feedback . unlike other workplace awards , there is no self - nomination or application process . to determine the winners , glassdoor evaluates company reviews shared by current and former employees over the past year . that means every comment , rating , and personal experience shapes the final outcome . at mongodb , leadership isn’t limited to titles—it ’s how we work . guided by our values and leadership commitment , we push ourselves to think big , act with ownership , and build trust every day . this recognition is proof that our approach is more than words on a page—it ’s shaping a culture where people are inspired to grow , innovate , and win together . our leaders are not only setting strategy and steering the business ; they are building an environment where people feel empowered to take risks , to challenge the status quo , and to achieve more than they thought possible . hear more from our employees “ i joined mongodb as the executive assistant to our ceo , dev ittycheria . during my time working with dev , i saw firsthand the transparent nature of our leadership team . though they are focused on the market opportunity in front of us and ensuring mongodb is set up for long - term success , it does not come at the expense of our people . it was a privilege to support the ceo and work closely with his leadership team who lead with our company values and focus on our people in everything they do . ” - ava thompson , executive support “ in my time here , i 've been fortunate to see and drive change at the individual level , but also see leadership acknowledge and push innovation at the top , underlining the value we place on continuously improving the way we do things at all levels . ” - charles shim , fp&a “ every quarter , i have honest conversations with leaders about whether i achieved the goals i set and why . my leaders here help me map out a career path , suggest opportunities i hadn’t considered , and provide feedback on how to align my personal goals with my professional growth . because of that , i feel i ’m growing in every way . ” - jin seo , customer success “ mongodb is a hybrid company . like many of our engineers , i work outside the company headquarters in new york city . i appreciate mongodb ’s approach to hybrid working and that the company leadership cares about the well - being of their employees . it seems there are companies that don’t seem to trust their employees to make decisions , such as which days to come into the office , so i ’m thankful for the autonomy i receive at mongodb to work in a way that ’s best for me . ” - andrew whitaker , engineering at mongodb , we continuously strive to deliver great results for our customers , live our values in everything we do , and demonstrate our leadership principles every day . because we 're not just building next - generation technology – we ’re building the next generation of leaders , too . visit our careers site to learn more about how you can transform your career at mongodb . \\n culture \\n simplify ai - driven data connectivity with mongodb and mcp toolbox \\n the wave of generative ai applications is revolutionizing how businesses interact with and derive value from their data . organizations need solutions that simplify these interactions and ensure compatibility with an expanding ecosystem of databases . enter mcp toolbox for databases , an open - source model context protocol ( mcp ) server that enables seamless integration between gen ai agents and enterprise data sources using a standardized protocol pioneered by anthropic . with the built - in capability to query multiple data sources simultaneously and unify results , mcp toolbox eliminates fragmented integration challenges , empowering businesses to unlock the full potential of their data . with mongodb atlas now joining the ecosystem of databases supported by mcp toolbox , enterprises using mongodb ’s industry - leading cloud - native database platform can benefit from streamlined connections to their gen ai systems . as businesses adopt gen ai to unlock insights and automate workflows , the choice of database is critical to meeting demands for dynamic data structures , scalability , and high - performance applications . mongodb atlas , with its fully managed , document - oriented nosql design and capabilities for flexible schema modeling , is the ultimate companion to mcp toolbox for applications requiring unstructured or semistructured data connectivity . this blog post explores how mongodb atlas integrates into mcp toolbox , its advantages for developers , and the key use cases for enabling ai - driven data solutions in enterprise environments . figure 1. mongodb as a source for mcp toolbox for databases . how it works the integration of mongodb atlas with mcp toolbox enables users to perform create , read , update , delete ( crud ) operations on mongodb data sources using the standardized mcp . beyond fundamental data management tasks , this integration also unlocks capabilities from mongodb ’s aggregation framework , enabling users to seamlessly execute complex data transformations , computations , and analyses . this empowers businesses to not only access and modify their data but also uncover valuable insights by harnessing mongodb ’s powerful query functionality within workflows driven by mcp toolbox . by combining the scalability and flexibility of mongodb atlas with mcp toolbox ’s ability to query across multiple data sources , organizations can develop advanced ai - driven applications , enhance operational efficiency , and uncover deeper analytical opportunities . the use of mongodb as both a source and a sink within mcp toolbox is simple and highly versatile , thanks to the flexibility of the configuration file . to configure mongodb as a data source , you can define it under the sources section , specifying parameters such as its kind ( \\\" mongodb \\\" ) and the connection ’s uniform resource identifier ( uri ) to establish access to your mongodb instance . sources : my - mongodb : kind : mongodb uri : \\\" mongodb + srv : / / username : password @ host . mongodb . net \\\" in the tools section , various operations — such as retrieving , updating , inserting , or deleting data — can be defined by linking the appropriate source , specifying the target database and dataset , and configuring parameters such as filters , projections , sorting , or payload structures . additionally , databases can act as sinks for storing data by enabling operations to write new records or modify existing ones , making them ideal for workflows where applications or systems need to interact dynamically with persistent storage . the toolsets section facilitates grouping related tools , making it easy to load and manage specific sets of operations based on different use cases or requirements . whether used for reading or writing data , the integration of databases via mcp toolbox provides a streamlined and consistent approach to managing and interacting with diverse data sources .\",\"datePublished\":null,\"dateLastCrawled\":null},{\"id\":\"https://api.langsearch.com/v1/#WebPages.5\",\"name\":\"KnotAPI Status. Check if KnotAPI is down or having problems. | StatusGator\",\"url\":\"https://statusgator.com/services/knotapi\",\"displayUrl\":\"https://statusgator.com/services/knotapi\",\"snippet\":\"is knot api down ? \\n current knot api status is up \\n we checked the official knot api status page 2 min. 24 sec . ago . learn more \\n recent knot api outages and issues \\n follow the recent outages and ...\",\"summary\":\"is knot api down ? \\n current knot api status is up \\n we checked the official knot api status page 2 min. 24 sec . ago . learn more \\n recent knot api outages and issues \\n follow the recent outages and downtime for knot api in the table below . \\n start time \\n type \\n length \\n message \\n details \\n knot api components and services \\n view details of the current knot api status below . \\n name \\n status \\n details \\n knot api card switcher api - production up \\n see more \\n knot api card switcher api - sandbox up \\n see more \\n knot api dashboard up \\n see more \\n knot api mobile sdk - android up \\n see more \\n knot api mobile sdk - ios up \\n see more \\n no outages or status changes in the last 24 hours \\n knot api status , last 24 hours : \\n 12:00 am \\n 6:00 am \\n 12:00 pm \\n 6:00 pm \\n 12:00 am \\n 12:00 am \\n 12:00 pm \\n 12:00 am \\n up : 24 hours \\n warn : 0 minutes \\n down : 0 minutes \\n maintenance : 0 minutes \\n knot api outage and status history \\n we've been monitoring knot api outages since june 13 , 2024 . \\n here 's the history of service outages we've observed from the knot api status page : \\n july 2024 \\n up \\n warn \\n down \\n maintenance \\n solutions for everyone \\n education \\n keep students and staff informed \\n reduce ticket volume \\n essential for remote learning \\n devops \\n shorten incident downtime \\n unify maintenance schedules \\n integrates with incident tools \\n it teams \\n reduce ticket volumes \\n improve transparency \\n shorten resolution times \\n instant enriched data from \\n 3 , 960 status pages \\n about our knot api status page integration \\n knot api is a service that status gator has been monitoring since june 2024 . over the past about 1 month , we have collected data on on outages that affected knot api users . when knot api publishes downtime on their status page , they do so across 5 components using 4 different statuses : up , warn , down , and maintenance which we use to provide granular uptime metrics and notifications . \\n many status gator users monitor knot api to get notified when it 's down , is under maintenance , or has an outage . you can get alerts by signing up for a free status gator account . \\n down notifications \\n if knot api is having system outages or experiencing other critical issues , red down notifications appear on the status page . in most cases , it means that core functions are not working properly , or there is some other serious customer - impacting event underway . \\n warning notifications \\n warn notifications are used when knot api is undergoing a non - critical issue like minor service issues , performance degradation , non - core bugs , capacity issues , or problems affecting a small number of users . \\n maintenance notifications \\n knot api posts separate notifications for planned maintenance work . status gator will notify subscribers when knot api enters a pre - planned maintenance window , keeping you up to date . \\n proactive maintenance feed \\n since knot api publishes a feed of proactive maintenance events on their status page , status gator will collect information about these events . maintenance events for all your services can be viewed within status gator as a unified feed . \\n status messages \\n when knot api posts issues on their status page , we collect the main headline message and include that brief information or overview in notifications to status gator subscribers . \\n status details \\n when knot api has outages or other service - impacting events on their status page , we pull down the detailed informational updates and include them in notifications . these messages often include the current details about how the problem is being mitigated , or when the next update will occur . \\n component status filtering \\n because knot api has several components , each with their individual statuses , status gator can differentiate the status of each component in our notifications to you . this means , you can filter your status page notifications based on the services , regions , or components you utilize . this is an essential feature for complex services with many components or services spread out across many regions . \\n frequently asked questions \\n is knot api down today ? \\n according to its status page knot api is currently up . you can check the most recent events in the ' recent outages and issues ' section above . \\n how can i get notified when knot api is not working or have outages ? \\n status gator can send you instant alerts by email , sms , slack , and more . sign up now , it 's free ! \\n how can i find out if knot api is having issues ? \\n there are two main options : you can check the status page or you can subscribe to status gator for free alerts and notifications when their status page changes . \\n knot api status page says the service is up , but i 'm having issues . what 's wrong ? \\n there may be several reasons for that : \\n an outage that hasn't been communicated yet via the knot api status page . \\n some local issues with a small group of accounts on the service side . \\n technical issues on your side , or problems with your software or isp . \\n a misconfiguration on your side . \\n we recommend contacting knot api customer support while checking everything on your side . \\n where do you get the official knot api status ? \\n we use the official status page . here are links to their status page and other helpful links : \\n knot api status page \\n knot api home page \\n @ knot apis \\n no outages or status changes in the last 24 hours \\n knot api status , last 24 hours : \\n 12:00 am \\n 6:00 am \\n 12:00 pm \\n 6:00 pm \\n 12:00 am \\n 12:00 am \\n 12:00 pm \\n 12:00 am \\n up : 24 hours \\n warn : 0 minutes \\n down : 0 minutes \\n maintenance : 0 minutes \\n knot api outage and status history \\n we've been monitoring knot api outages since june 13 , 2024 . \\n here 's the history of service outages we've observed from the knot api status page : \\n july 2024 \\n up \\n warn \\n down \\n maintenance\",\"datePublished\":null,\"dateLastCrawled\":null},{\"id\":\"https://api.langsearch.com/v1/#WebPages.6\",\"name\":\"GitHub - natir/knot: KNOT: Knowledge Network Overlap exTraction is a tool for the investigation of fragmented long read assemblies.\",\"url\":\"https://github.com/natir/knot\",\"displayUrl\":\"https://github.com/natir/knot\",\"snippet\":\"natir / \\n knot \\n knot : knowledge network overlap extraction is a tool for the investigation of fragmented long read assemblies . \\n code \\n natir / knot \\n files \\n demo \\n demo \\n images \\n images \\n knot \\n...\",\"summary\":\"natir / \\n knot \\n knot : knowledge network overlap extraction is a tool for the investigation of fragmented long read assemblies . \\n code \\n natir / knot \\n files \\n demo \\n demo \\n images \\n images \\n knot \\n knot \\n .gitattributes \\n .gitattributes \\n .gitignore \\n .gitignore \\n license \\n license \\n manifest.in \\n manifest.in \\n readme.md \\n readme.md \\n conda _ env . yml \\n conda _ env . yml \\n requirements.txt \\n requirements.txt \\n setup.py \\n setup.py \\n knot \\n knot : knowledge network overlap extraction is a tool for the investigation of fragmented long read assemblies . \\n knot is described in article graph analysis of fragmented long - read bacterial genome assemblies accepted in bioinformatics ( preprint version ) \\n give an assembly and a set of reads to knot , it will output an information - rich contig graph in csv format that tells you about adjacencies between contigs . \\n input \\n output \\n usage \\n run knot \\n generate html report on knot result \\n installation \\n install with conda \\n install by create conda environement \\n install without conda \\n update \\n conda installation \\n non - conda installation \\n limitations \\n more details \\n pipeline presentation \\n output description \\n citation \\n you can find a demo dataset and instructions for using it , in the demo folder of this repository . \\n input \\n long reads ( corrected or not ) fasta ( no fastq allowed ) \\n contigs ( in fast a ) from the same assembler \\n ( this one is optional : ) assembly graph ( in gfa 1 ) produced by an assembler \\n output \\n knot outputs an augmented assembly graph ( aag ) . the aag is a directed graph where nodes are contigs . an edge is present if two contigs overlap or , if in the original string graph of the reads , there exists a path between extremities of both contigs . \\n the aag is present in the { output prefix } _ aag . csv . ( note : the other gfa files produced by knot are not the aag ) \\n we recommend that you use the html report to look at the aag first ( see below on how to generate that report ) but the raw csv file can also be parsed directly . \\n output aag format is in csv format with 8 column : \\n tig 1 : tig name and extremity use in format { tig name } _ { extremity } e.g. tig 00000001 _ begin \\n read 1 : read id use to search path for tig1 extremity \\n tig 2 : other tig name and extremity \\n read 2 : read id use to search path for tig2 extremity \\n nb _ read : nb _ read in path between read 1 and read 2 ( include ) \\n nb _ base : nb _ base in path between read 2 and read 2 \\n paths : id of read in path found between read 1 and read 2 , separated by ; \\n n bread _ contig : number of read assign for each contig in format { tig name } : { nb of read in paths assign to contig } / { nb of read in tig } not _ assign used to read not assigned to a contig , separated by ; . \\n this output can be used to manually investigate the result of an assembly . short paths between contigs are likely true adjacencies . long paths are likely repeat - induced . \\n more information about other file generated by knot are available in output description \\n usage \\n assume that \\n long reads are stored in raw _ reads . fast a \\n contigs are stored in contigs . fast a \\n ( optional ) contig graph is stored in contigs . gfa \\n run knot \\n then run knot as : \\n knot -r raw _ reads . fast a -c contigs . fast a [ - g contigs . gfa ] -o { output prefix } -- -j { number of para lelle jobs avaible } [ any snakemake parameter you like ] \\n knot will run a snakemake pipeline and produce { output prefix } _ aag . csv see output section for more details , and a directory { output prefix } _ knot where intermediate file are store . \\n you can use corrected long reads in place of raw _ reads with -m option . \\n full command line usage : \\n usage : knot [ - h ] -c contigs [ - g contigs _ graph ] \\n ( - r raw _ reads | -c correct _ reads ) -o output \\n [ - - search - mode { base , node } ] \\n [ - - contig - min - length contig _ min _ length ] [ - - read - type { pb , ont } ] \\n [ - - help - all ] \\n optional arguments : \\n - h , --help show this help message and exit \\n -c contigs , - - contigs contigs \\n fasta file than contains contigs \\n -g contigs _ graph , - - contigs _ graph contigs _ graph \\n contigs graph \\n -r raw _ reads , - - raw - reads raw _ reads \\n read used for assembly \\n -c correct _ reads , - - correct - reads correct _ reads \\n read used for assembly \\n -o output , --output output \\n output prefix \\n - - search - mode { base , node } \\n what path search optimize , number of base or number of \\n node \\n - - contig - min - length contig _ min _ length \\n contig with size lower this parameter are ignored \\n - - read - type { pb , ont } type of input read , default pb \\n - - help - all show knot help and snakemake help \\n in addition , snakemake parameters can be add after - - . \\n generate html report on knot result \\n you can generate a html report knot _ report . html on knot information generate previously with this command : \\n knot . analysis -i { output prefix give to knot previously } -c -p -o knot _ report . html \\n if -c is present , knot . analysis run a path classification , based on path length and composition see manuscript for more details . \\n if -p is present , knot . analysis run a hamilton path search , see manuscript for more details . \\n installation \\n install with conda \\n recommended solution ( 1 command , 2 minutes ) \\n if bioconda channel is set up you have just to run this command : \\n conda install knot \\n install by create conda environement \\n wget https : / / raw . githubusercontent . com / nat ir / knot / v 1 . 3 / conda _ env . yml \\n git _ lfs _ skip _ smudge = 1 conda env create -f conda _ env . yml \\n activate environement : \\n conda activate knot _ env \\n unactivate environement : \\n conda deactivate \\n install without conda \\n requirements : \\n python > = 3.6 \\n snakemake > = 5.3 \\n ya crd avaible in bioconda or cargo > = 0.6 \\n fpa avaible in bioconda or cargo > = 0.5 \\n minimap2 avaible in bioconda \\n instruction : \\n git _ lfs _ skip _ smudge = 1 pip3 install git + https : / / git hub . com / natir / knot . git \\n how to update an already - installed knot ? \\n conda installation \\n the recommended way to update this tool is to remove the conda environement and reinstall it : \\n source deactivate \\n conda env remove -n knot _ env \\n wget https : / / github . com / nat ir / knot / raw / master / conda _ env . yml \\n conda env create -f conda _ env . yml \\n non - conda installation \\n pip3 install --upgrade git + https : / / git hub . com / natir / knot . git \\n limitations \\n this tool has mainly be tested on bacterial genomes only , where it takes 30 minutes to run ( in most case ) . in principle it should also run on larger genomes . but then we expect that the produced augmented assembly graphs will need to be automatically parsed , as their visualization will be more challenging . \\n more details \\n pipeline presentation \\n legend : \\n input # 2 d 882 d \\n minimap2 # a a 3939 \\n fpa # a a 7539 \\n ya crd # 27556 c \\n output # 5 d 2971 \\n pipeline internal tool # ffd 300 \\n output description \\n if you run knot with raw reads : \\n { output prefix } _ aag . csv # aag result in format describe earlier \\n { output prefix } _ knot # knot working directory \\n ├ ── contigs . fast a # symbolic link to contig sequence provide as input \\n ├ ── con tigs _ filtred . fast a # contigs keept in analysis filter on length \\n ├ ── contigs _ filtre d . gfa # corresponding graph generated by fpa ( from con tigs _ filtred . paf , no containment , no internal match ) \\n ├ ── con tigs _ filtred . paf # corresponding paf file made using minimap2 \\n ├ ── contigs _ graph . gfa # symbolic link to contig graph provide as input \\n ├ ── ext _ search . csv # read associated to each contig extremity \\n ├ ── raw _ reads . fast a # symbolic link to raw read provide as input \\n ├ ── raw _ reads . paf # self mapping of raw _ reads \\n ├ ── raw _ reads _ splited . fast a # raw reads without not covered sequence provide by ya crd \\n ├ ── raw _ reads _ splited . gf a # overlap graph generate by fpa on raw _ reads _ splited self mapping \\n ├ ── raw _ reads _ splited . paf # self mapping of raw _ reads _ splited \\n ├ ── raw _ reads . ya crd # ya crd output on raw _ reads \\n └ ─ ─ read 2 asm . paf # mapping of read on con tigs _ filtred \\n if you run knot with corrected reads : \\n { output prefix } _ aag . csv # aag result in format describe earlier \\n { output prefix } _ knot # knot working directory \\n ├ ── contigs . fast a # symbolic link to contig sequence provide as input \\n ├ ── con tigs _ filtred . fast a # contigs for which we have found overlaps between them \\n ├ ── contigs _ filtre d . gfa # corresponding graph generated by fpa ( from con tigs _ filtred . paf ) \\n ├ ── con tigs _ filtred . paf # corresponding paf file made using minimap \\n ├ ── contigs _ graph . gfa # symbolic link to raw read provide as input \\n ├ ── ext _ search . csv # read associated to each contig extremity \\n ├ ── raw _ reads _ splited . fast a # symbolic link to corrected read provide as input \\n ├ ── raw _ reads _ splited . gf a # overlap graph generate by fpa on raw _ reads _ splited self mapping \\n ├ ── raw _ reads _ splited . paf # self map pig of raw _ reads _ splited \\n └ ─ ─ read 2 asm . paf # mapping of read on contigs _ filter d \\n citation \\n if you use knot in your research , please cite the following publication : \\n pierre marijon , rayan chikhi , jean-stéphane varré , graph analysis of fragmented long - read bacterial genome assemblies , bioinformatics , btz 219 , https : / / doi . org / 10 . 1093 / bioinformatics / btz 219 \\n @ article { marijon 2019 , \\n doi = { 10 . 1093 / bioinformatics / btz 219 } , \\n url = { https : / / doi . org / 10 . 1093 / bioinformatics / btz 219 } , \\n year = { 2019 } , \\n month = { mar } , \\n publisher = { oxford university press ( { o up } ) } , \\n author = { pierre marijon and rayan chikhi and jean - st { \\\\ ' { e } } phane varr { \\\\ ' { e } } } , \\n editor = { john hancock } , \\n title = { graph analysis of fragmented long - read bacterial genome assemblies } , \\n journal = { bioinformatics } \\n } \\n knot : knowledge network overlap extraction is a tool for the investigation of fragmented long read assemblies . \\n topics \\n graph assembly long - reads \\n releases 2 \\n languages \\n html 95 . 8 % \\n python 4 . 2 %\",\"datePublished\":null,\"dateLastCrawled\":null},{\"id\":\"https://api.langsearch.com/v1/#WebPages.7\",\"name\":\"Nature APIs (Free Tutorials, SDK Documentation & Pricing) | RapidAPI\",\"url\":\"https://rapidapi.com/search/nature\",\"displayUrl\":\"https://rapidapi.com/search/nature\",\"snippet\":\"nature apis \\n browse the best premium and free apis on the world 's largest api hub . read about the latest api news , tutorials , sdk documentation , and api examples . rapidapi offers free apis all ...\",\"summary\":\"nature apis \\n browse the best premium and free apis on the world 's largest api hub . read about the latest api news , tutorials , sdk documentation , and api examples . rapidapi offers free apis all within one sdk . one api key . one dashboard . \\n edamam food and grocery database \\n this api provides you with tools to find nutrition and diet data for generic foods , packaged foods and restaurant meals . in addition it employs nlp ( natura l language processing ) which allows for extraction of food entities from unstructured text . covered use cases : - search for a food by keyword , food name or upc / barcode - sourcing of nutrition facts for a given food , including : macro and micro nutrients , allergen labels , lifestyle and health labels - search for a food by given ... \\n 9.7 757 ms 100 % \\n recipe - food - nutrition \\n the spoonacular nutrition , recipe , and food api allows you to access over 365 , 000 recipes and 86,000 food products . our food ontology and semantic recipe search engine makes it possible to search for recipes using natura l language queries , such as \\\" gluten free brownies without sugar \\\" or \\\" low fat vegan cupcakes . \\\" you can automatically calculate the nutritional information for any recipe , analyze recipe costs , visualize ingredient lists , find recipes for what 's in your fridge , find recipes based on special diets , nutritional requirements , or favorite ingredients , classify recipes into types and cuisines , convert ingredient amounts , or even compute an entire meal plan . with our powerful api , you can create many kinds of food and especially nutrition apps . special diets / dietary requirements currently available include : vegan , vegetarian , pescetarian , gluten free , grain free , dairy free , high protein , low sodium , low carb , paleo , primal , ketogenic , fodmap , and whole 30 . we will soon be adding weight watcher points , too . \\n verified ✓ \\n 9.9 486 ms 100 % \\n twinword text analysis bundle \\n one api for all your text analysis needs . sentiment analysis , topic tagging , lemmatizer , and much more . various nlp tools all with one plan . use natura l language processing to analyze and understand human sentences . \\n verified ✓ \\n 9.6 213 ms 100 % \\n text summarization \\n text summarization api provides professional text summarizer service which is based on advanced natura l language processing and machine learning technologies . it can be used to summarize short important text from the url or document that user provided . if you want test our automatic text summarization service , you can use our free automatic text summarizer online demo : http : / / text summarization . net / text - summarizer \\n 9.6 301 ms 100 % \\n nutrition by api - ninjas \\n natura l language api to extract nutrition data from any text . see more info at https : / / api - ninjas . com / api / nutrition . \\n 9.5 391 ms 98 % \\n chatgpt api \\n chatgpt api is an advanced chatbot solution powered by gpt technology , offering lightning - fast response times and cost - effective customer service solutions for businesses of all sizes . with chatgpt api , businesses can streamline their customer interactions , reduce response times , and improve customer satisfaction with personalized and natura l - sounding chat conversations . using the latest gpt algorithms , chatgpt api generates responses that are tailored to the user 's needs , providing an engag . . . \\n 9.5 4 , 824 ms 100 % \\n zerogpt \\n zerogpt api or chatgpt detector it is an api designed to detect whether a given text has been generated by a gpt language model or written by a human . it utilizes various natura l language processing techniques to analyze the text and identify patterns and characteristics that are indicative of gpt - generated content . the api can be integrated into various applications and systems to help identify and filter out potentially misleading or malicious content generated by gpt models . # chatgpt # . . . \\n 9.5 3 , 696 ms 100 % \\n chatgpt - gpt 4 ai chatbot \\n introducing chatgpt - gpt-4 ai chatbot , a cutting - edge conversational solution designed to revolutionize your user engagement experience . leveraging the powerful gpt-4 technology , our ai chatbot ensures seamless and natura l interactions with your users while significantly reducing operational costs . cost - effectiveness : chatgpt - gpt-4 ai chatbot offers an affordable solution that helps businesses reduce overheads associated with customer support services . by automating routine queries and ta . . . \\n 9.8 2 , 697 ms 100 % \\n microsoft text analytics \\n an ai service from microsoft azure that enables you to unlock insights from natura l language text using sentiment analysis , named entity recognition , language detection , and key phrase extraction in multiple languages \\n 9.7 336 ms 100 % \\n text api \\n a text extraction , manipulation , and analysis api . putting the power of natura l language processing ( nlp ) in every developers hands . \\n 9 30 , 661 ms 100 % \\n sentiment analysis \\n multilingual sentiment analysis of texts from different sources ( blogs , social networks , . . . ) . besides polarity at sentence and global level , sentiment analysis uses advanced natura l language processing techniques to also detect the polarity associated to both entities and concepts in the text . sentiment analysis also gives the user the possibility of detecting the polarity of user - defined entities and concepts , making the service a flexible tool applicable to any kind of scenario . additionally , sentiment analysis detects if the text processed is subjective or objective and if it contains irony marks [ beta ] , both at global and sentence level , giving the user additional information about the reliability of the polarity obtained from the sentiment analysis . \\n 8.8 1 , 040 ms 100 % \\n recipe \\n the web knox recipe api allows you to access over 330,000 recipes . it allows users to search for recipes using natura l language such as \\\" gluten free brownies without sugar \\\" . furthermore , several widgets to visualize ingredient lists , price breakdowns , this food api also contains thousands of information bits about ingredients such as nutrition , prices , tips , and more . \\n 8.9 263 ms 100 % \\n edamam nutrition analysis \\n the nutrition analysis api and database uses natura l language processing and semantically structured data . \\n 9.4 812 ms 100 % \\n diffbot \\n diffbot extracts data from web pages automatically and returns structured json . for example , our article api returns an article 's title , author , date and full - text . use the web as your database ! we use computer vision , machine learning and natura l language processing to add structure to just about any web page . \\n 8.9 396 ms 100 % \\n rapid translate \\n translate texts between 50 + natura l languages . \\n 9.4 217 ms 100 % \\n realistic text to speech \\n experience the future of speech technology with our realistic text to speech service ! transform written content into lifelike audio with unparalleled accuracy and natura l ness . our advanced ai - driven system ensures flawless pronunciation , intonation , and emotion , making every word come alive . whether for e - learning , audiobooks , customer support , or accessibility needs , our realistic text to speech service delivers a seamless and engaging audio experience like never before . embrace the power of . . . \\n 9.3 2 , 735 ms 99 % \\n text to speech pro \\n convert text into natura l - sounding speech using an api - realtime & multi language \\n 9.3 704 ms 100 % \\n tourist attraction \\n discover the world 's wonders with ease using the tourist attraction api . unleash a wealth of information about popular attractions worldwide , including historical sites , natura l landmarks , museums , and more . seamlessly integrate this api to provide users with detailed insights , captivating images , and essential details , enriching their travel experiences like never before . whether you 're crafting travel apps , tour guides , or adventure platforms , the tourist attraction api is your gateway to e . . . \\n 9.4 2 , 073 ms 80 % \\n text to speach api \\n the text-to-speech api is a powerful tool that converts written text into natura l - sounding speech , allowing applications and devices to communicate with users through spoken language . \\n 9.4 308 ms 100 % \\n evaluate expression \\n multi-purpose natura l language calculator \\n 8.9 520 ms 100 % \\n detect skin disease \\n the input natura l skin images are used to predict the classification of skin diseases , and common diseases such as ` acne ` , ` actinic keratosis ` , ` alopecia androgenetica ` , ` alopecia areata ` , ` bullous dermatosis ` , ` chloasma ` , ` corn ` , ` dermatofibroma ` , ` eczema dermatitis ` , ` erysipelas ` , ` erythema multiforme ` , ` folliculitis ` , ` furuncle ` , ` haemangioma ` , ` herpes ` , ` herpes ` ` simplex ` , ` iga vasculitis ` , ` keloid ` , ` keratosis follicularism ` , ` lichen planus ` , ` lupus erythematosus ` , ` molluscum contagiosum . . . \\n 8.9 2 , 681 ms 100 % \\n chatgpt ai chat bot \\n this api provides users with access to the latest version of chatgpt , a cutting - edge language model trained by openai . this means that users can take advantage of the most advanced natura l language processing capabilities available , allowing for more accurate and effective communication with users or customers . one of the key advantages of this api is its speed and reliability . chatgpt is known for its fast response times and the ability to handle large volumes of requests without experien ci . . . \\n 9.3 4 , 694 ms 100 % \\n gpt-4 \\n introducing the gpt-4 api – your gateway to cutting - edge ai ! unleash the power of the future with our state - of - the - art language model . elevate your applications with natura l language understanding , content generation , and more . elevate your ai capabilities with gpt-4 today ! \\n 8.5 13 , 673 ms 82 % \\n face swap image transformation api \\n the face swap image transformation api is a powerful and versatile tool that allows developers to seamlessly swap faces between source and target images . this api leverages cutting - edge computer vision and deep learning technologies to detect and replace faces while preserving the natura l appearance and quality of the images . whether you want to create humorous memes , personalize photos , or enhance your applications with facial manipulation capabilities , this api has you covered . \\n 8.7 7 , 365 ms 88 %\",\"datePublished\":null,\"dateLastCrawled\":null},{\"id\":\"https://api.langsearch.com/v1/#WebPages.8\",\"name\":\"Corporate information | Knot co.,ltd.\",\"url\":\"https://www.knot-inc.co.jp/en/company/\",\"displayUrl\":\"https://www.knot-inc.co.jp/en/company/\",\"snippet\":\"company \\n even as digitization advances and times change , the most important thing in promotion is to provide \\\" experiences that create the best from scratch \\\" . \\n it 's an \\\" experience \\\" that people...\",\"summary\":\"company \\n even as digitization advances and times change , the most important thing in promotion is to provide \\\" experiences that create the best from scratch \\\" . \\n it 's an \\\" experience \\\" that people share and transmit from all over the place , in their favorite cafes , in nature destinations , and in stadiums filled with huge crowds . \\n in all areas , knot aims to promote the creation of \\\" experiences that create the best from scratch \\\" that produce new discoveries and excitement . \\n representative greetings \\n knot co . , ltd. was founded in 2002 in shibuya , a place of origin for information and culture . this is because that i wanted to work as close as possible to shibuya , where young people gather to spread information and culture . \\n we are a company where young people play an active role , and we always value freedom and the stance \\\"it 's ok to do anything at any time \\\" . in my opinion , as far as we can help our clients , we can do what we really like . as time goes on , the methods and the way of thinking for promotion evolve rapidly , and that is why , today we have a wide range of businesses and business areas . \\n in recent years , we have developed various businesses in-house with the concept of \\\"let 's make shibuya more exciting by ourselves ! \\\" . \\\" creating experiences \\\" is the most important aspect of promotion , whether digital or real . every knot employee and staff member can grow together with customers through various experiences . we want to remain that kind of company . \\n knot co . , ltd. \\n representative director yoshiaki tanigawa \\n corporate profile \\n company name \\n knot co . , ltd. \\n address \\n namiki bashi building , 3 - 15 - 6 shibuya , shibuya - ku , tokyo 150 - 0002 \\n establishment \\n march 2002 \\n capital stock \\n 10 million yen \\n representative \\n representative director yoshiaki tanigawa \\n main bank \\n mufg bank , roppongi branch \\n sumitomo mitsui banking corporation , shibuya - ekimae branch \\n mizuho bank , aoyama branch \\n business description \\n advertising agency \\n sales promotion planning and implementation \\n planning , creation and production of events and exhibitions \\n planning , creation and production of videos \\n planning design and production \\n planning and production of web content \\n application planning and development \\n licenses \\n acquired iso 27001 certification ( headquarters only ) : is 756104 / iso 27001 \\n privacy mark accreditation : no . 10862029 ( 07 ) \\n general construction license : no . 136511 \\n general worker dispatching business permission number : 派 13 - 316757 \\n security services tokyo public safety commissioner association permission number : 30004821 \\n tokyo public safety commissioner association secondhand dealer permit number : 303312215380 \\n liquor license 渋法 number : 554 \\n real estate transaction business license tokyo governor ( 1 ) no . 110950 \\n access \\n tokyo office \\n namiki bashi building , 3 - 15 - 6 shibuya , shibuya - ku , tokyo 150 - 0002 \\n 9 minutes walk from shibuya station \\n 10 minutes walk from daikanyama station \\n 13 minutes walk from ebisu station \\n osaka office \\n u mega e - chuo bldg . 3 f , 4 - 4 - 18 nishitenma , kita - ku , osaka \\n 8 minutes walk from minami morimachi station on osaka metro tanimachi line \\n 10 minutes walk from higashi umeda station on osaka metro tanimachi line \\n 10 minutes walk from osaka tenmangu station on jr tozai line\",\"datePublished\":null,\"dateLastCrawled\":null},{\"id\":\"https://api.langsearch.com/v1/#WebPages.9\",\"name\":\"The Knot: Manage your Wedding Registries – The Knot\",\"url\":\"https://helpcenter.theknot.com/hc/en-us/articles/9717988654612-The-Knot-Manage-your-Wedding-Registries\",\"displayUrl\":\"https://helpcenter.theknot.com/hc/en-us/articles/9717988654612-The-Knot-Manage-your-Wedding-Registries\",\"snippet\":\"the knot : manage your wedding registries \\n to manage and link all of your wedding registries , go to your wedding registry page . you can create a new registry , connect an existing one , and customi...\",\"summary\":\"the knot : manage your wedding registries \\n to manage and link all of your wedding registries , go to your wedding registry page . you can create a new registry , connect an existing one , and customize your registry page and url before sharing with your guests . \\n if your registry did not automatically link , let 's walk through how to add your registry manually to your account : \\n 1. log in to your account \\n 2. click into your registry dashboard \\n 3. click add store registries \\n 4. scroll down the page to find option two : link an existing registry \\n 5. select a store in the drop down list ( if not on the list , scroll all the way down and choose + add another store ) \\n 6. add a store name ( this is what will appear in the gift provider section of your registry page ) \\n 7. enter the name and the unique url for your registry page on the retailer 's site \\n 8. click add it now please note , you may need to allow 15 - 20 mins for everything to fully connect after this process . \\n if you need any help or have any questions with managing your registry , please feel free to reach out to us at help @ the knot . com\",\"datePublished\":null,\"dateLastCrawled\":null},{\"id\":\"https://api.langsearch.com/v1/#WebPages.10\",\"name\":\"Observable API Proposal | Hacker News\",\"url\":\"https://news.ycombinator.com/item?id=36909525\",\"displayUrl\":\"https://news.ycombinator.com/item?id=36909525\",\"snippet\":\"controversial but brave take : i think adding this to javascript is a bad idea . it ’s not that observables are inherently bad . it ’s just that they produce some of the least intuitive code imaginabl...\",\"summary\":\"controversial but brave take : i think adding this to javascript is a bad idea . it ’s not that observables are inherently bad . it ’s just that they produce some of the least intuitive code imaginable . i ’ve never seen a codebase with observables where i didn’t question the engineering team ’s technical motivations . the three horsemen of unmaintainable javascript have always been generators , rxjs , and redux . \\n i can’t quite find an accurate metaphor to describe my experience with these data design patterns , but the first that comes to mind is “ hollywood accounting . ” it ’s always the same hat trick . take a straightforward task of single directional data flow and subdivide it up into a has kellian map / reduce game of musical chairs . \\n don’t get me wrong , i understand the importance of having observability in data streams . but we already have them via the readablestream and transformstream apis . combined with native proxies and we ’re just about covered on the use - cases described in the examples section . \\n i ’m also suspect of the lack of insight in this explainer on why the two previous proposals were rejected . we need more concrete evidence of why an additional api should be the answer to the question of whether there are too many competing observable frameworks . this isn’t a jquery or bluebird promises scenario where the observerable paradigm is so entrenched in contemporary engineering , or even that a sizable amount of software development would require a third - party library to fill in the gap . \\n javascript has many missing features . this is not one of them . \\n as someone who has been using rx since 2014 ( with a heavy heart ) i must agree with you here . 9 out of 10 times there ’s a simple , more boring way of solving the problem . i want boring in my life . boring is good . \\n the idea that reading code is harder than writing it can take an extreme form with this style of coding imho . \\n ( my other issue is that for me frp style code , esp . with rx , is just so much fun to write . ) \\n > it ’s just that they produce some of the least intuitive code imaginable . the three horsemen of javascript have always been generators , rxjs , and redux . \\n it took the author of rxjava months to understand the concepts . and he had the author of rx . net to explain them to him [ 1 ] \\n it 's also strange is that what we realy want is excel - like reativity . but instead we 're always getting rx - like reactivity . \\n [ 1 ] from his book : https : / / pbs . twimg . com / media / c 0 m - u 1 dx ca adts 3 ? format = jpg & name = . . . \\n a time ago i had a project where we had an intense tree - like data structure where at any given level there may be a finite async - stream . basically recursively needed to await streams until they finished . \\n i was using for rxdb based on rxjs , so after a couple nights of banging my head i went into the rxjs chat and asked for help . one of the maintainers of the library who worked at ms said it was a perfect problem and i think i nerd - baited him into helping out . . . \\n ... we ended up spending like a week on it going back and forth , and neither of us could figure it out . the code we ended up with was frightening . \\n i 'm guessing jafar is jafar husain , the original evangelist of observables in javascript ? \\n https : / / www . youtube . com / watch ? v = lil 4 y ccxr yc \\n i don't think that the problem is that javascript may or may not have this feature , it 's not even that the language is large and all - encompassing ; it 's that mixing and matching features is highly appealing and very rarely works out well in practice . \\n javascript is not really a single language built around a single specific style or set of needs any more . in this day and age it 's an amalgamation of different techniques and styles . you've got classic inheritance and composition for your oop crowd ; you've got your map and reduce for your functional crowd ; you've even got your observables for your reactive crowd . \\n this is all well and good , but i 've found that it 's hard to write some practical code that blends styles . at some point it 's tempting to start adding types , generics and dependency management into a functional project , but it 's my experience that this blending ends up getting in the way of itself . similar story for wanting to do things like having a service that listens to queues in an async way with sync rest apis . it seems like having a common set of middleware would make it easy to support both layers ; however this is easier said than done . these things sort of work but it feels deeply unsatisfying , requiring constant switching between observable and async / await styles with error handling being a constant concern . \\n i tend to agree . observables are incredibly powerful , so they seem like they _ might _ be a good fit for some use cases where you 're dealing with streams of events . and even then , you have to be really determined to not make a mess . for day - to - day event handling , they usually feel like overkill and become really difficult to understand . like , i don't _ want _ to use map , filter , etc to handle non - iterable stuff . it feels clever and cool on the surface but weird and brain - knot - inducing once you look more deeply at it . \\n the way they show off observables here is solves a lot of problems , but despite offering up svelte as an example of observables , it doesn't seem to aim to solve the problem that svelte stores do . \\n what i really want is a trivial way to say \\\" fire this callback whenever this variable changes . \\\" \\n mobx actually enables this w / o too much work , and svelte stores are a really nice syntaxical wrapper around the concept . \\n heck just give me what c # had back in 2002 and i 'd be happy . \\n > fire this callback whenever this variable changes \\n ouch , welcome to callback hell :( \\n futures would be slightly better . the least painful approach to things like that . to my mind , is an explicit event loop , and posting events on a change . \\n been there , helped design an entire embedded runtime based [ 1 ] around it , didn't mind it . \\n fwiw eventing systems are not the same as callback hell . \\\" tell me when this variable changes \\\" is the heart of a lot of really well engineered systems , including high performance hardware io . ( fill this buffer w / o bothering the cpu , when the buffer is full , call this function to process its contents ) . \\n eventing systems are nice . \\n > the least painful approach to things like that . to my mind , is an explicit event loop , and posting events on a change . \\n that is how windows works under the covers . \\n events are just syntactic sugar on top if that , in replacement of a giant switch / case statement . \\n [ 1 ] https : / / meandering thoughts . hashnode . dev / cooperative - multi tas . . . \\n my experience has been a total opposite . i 've been able to deliver quite complex features in a couple of lines of vert readable code thanks observables . of course , you can write terrible code with it , but the same goes for every technology . \\n i think that this presentation from netflix engineering team is still the best demonstration of how productive you can be wit rxjs : https : / / you tu . be / faz jsx cy kps \\n maybe it 's because i work on embedded system where i only have to worry about a single process , but i find observables really ergonomic . \\n \\\" if / else \\\" are a core construct in programming languages . observables add \\\" when \\\" , which i think is just as essential . whenever someone describes an autonomous system , they will use \\\" when x , do y \\\" . so it makes sense to me that code follows that . \\n a lot of the time i just want to write a piece of code that and plug it into the system without having to worry about coupling or its effect on other parts of the code . most of the time i don't have clear requirements , and need to stay flexible . \\n for example , new requirement to turn off the lcd after x minutes of inactivity , and turn it back on when the user presses a button ? i just create a new component ( instanced based on a configuration flag ) , plug it into the event bus reacting to button press events , and call it a day , without having to worry about something else breaking , often without even having to read existing code ( except how to get notified of the event ) . \\n even when modifying existing code , it 's easier to replace an event , easy to find which components are depending on that event , etc. \\n i dont think this should be considered controversial . this sounds like a well balanced opinion , and is for sure one i share . \\n javascript has many missing features . this is not one of them . \\n > it ’s just that they produce some of the least intuitive code imaginable . \\n i agree because i have seen this a lot . \\n > javascript has many missing features . this is not one of them . \\n while i do agree that abusing observable might leads to messy code , it 's very valuable in highly interactive apps . it provides proper abstraction / algebra which letting you tackle problems like tripple click , which might be extremely tedious to solve otherwise . \\n and interactivity is one of the natrual thing modern browser should empower developer to achieve ( at least for non - die - hard no - js person ) . \\n > but we already have them via the readablestream and transformstream apis . \\n i do appreciate that you appreciate simplicity and this sentiment in general . but i feel similar sentiments that led javascript to stagnent for a long time ( es 6 is just es4 but more than a decade later ) . \\n people like douglas crockford found the parity in javascript and lisp , and summarized the beauty in his works . while his book is one of my favorite programming book , the sentiment ( javascript don't need features because of closure , lisp - like and all that ) was so popular at time , which probably contributes to the stagnant . \\n ( microsoft and friends was probably happy about this that the web wasn't taking over so fast and they can shit everybody with ie6 for years , and then the mobile and their walled gardens were taking over . in other word , the web had even greater potential in between ie6 and mobile era ) \\n people could really try re - implement their react apps without modern tooling to feel the pain : no es6 module and abuse closure then cat the all files into one giant ball , only to mess up the order and dependencies . or without reactivity , updating states everywhere which leads to confusing bugs that making apps out of sync . , etc \\n > the three horsemen of unmaintainable javascript have always been generators , rxjs , and redux . \\n redux produces the easiest to follow code when following best practices . it ’s boring and works extremely well for its purpose . \\n generators may get a bad wrap but async / await are just generators with a different syntax — at least in js land . would you argue the same for async / await ? \\n i ’ve seen this comparison to async / await a few times and i ’m not sure how accurate it actually is . it ’s true that async functions can be poly filled via generators , but from what i understand that ’s more of a conceptual transpilation by tools like babel , rather than a runtime implementation . \\n imo the ` await ` keyword is clever abstraction that can make asynchronous code easier to understand in a synchronous way . and unlike the collection - oriented ceremony of generators , calling await on an expression doesn’t imply anything more than the presence of a ` then ` method on an object . \\n anything with a ` then ` method can be awaited , and so native promises aren’t actually all the special or sacred . invoking await on an expression involves no extra machinery , only that a promise - like object is returned . \\n and the ` async ` keyword is even better . it ’s completely optional ! this keyword only has two effects : allowing the ` await ` keyword in a function scope , and implicitly returning a promise . \\n there ’s a secret pleasure in all this too . a series of awaited promises can be wrapped into a single async function . and there ’s no need for multiple error checking steps either . all async functions return a promise , so we can wrap the function single try / catch block , or even daisy - chain another promise on the ` catch ` method . all the pieces fit into each other , and most of them are optional . \\n meanwhile in generator land , we’ve got cognitive overload in spades . yield can only be called from inside a generator , yes that little asterisk next to the function name you might at first glance mistake for an errant multiplication symbol . sorry , there ’s these things called symbols too . any object can be made yield able …orwasititerable…byplacingthespecialsymbolonanobjectclassasaninterpolatedmethodwhichreturnsaniterable . i’mnotmakingthisup . \\n imagine teaching this to a junior developer who ’s spent over a year programming asynchronous code and never once needing a generator . the tide - level for problems solved with generators is always waist - deep , always introduced as a secondary step to achieving another goal . \\n generators are almost always hints of a design - flaw introduced much earlier in development , usually by an engineer with enough experience to write code , but not nearly enough to understand how it works . \\n i agree with your point . on \\n > anything with a ` then ` method can be awaited , and so native promises aren’t actually all the special or sacred . invoking await on an expression involves no extra machinery , only that a promise - like object is returned . \\n note that _ anything _ can be awaited in js . \\n ` ` ` const x = await null ; console . log ( x ) ` ` ` \\n huh wow ! i did not know that ! i think typescript always kept this hidden from me , but it makes sense . another perk of ` await ` is that it collapses all promises into their final value , regardless of how many nested pending promises are expressed : \\n const foo = await promise . resolve ( promise . resolve ( \\\" abc \\\" ) ) \\n console . log ( foo . length ) // 3 \\n it 's not ` await ` which is doing that ; it 's the promises themselves . for example : \\n promise . resolve ( promise . resolve ( \\\" abc \\\" ) ) . then ( console . log ) \\n this will print ` \\\" abc \\\" ` , not ` promise . resolve ( \\\" abc \\\" ) ` . \\n what ’s wrong with generators ? \\n i get asked this question a lot — i help maintain redux - saga . \\n i recently gave a talk where this question came up : https : / / you tu . be / urbq lg j _ 6 mi ? t = 2166 \\n i ’ve also imposed generators on a lot of colleagues . \\n i think they are mostly misunderstood and potentially in the realm of being “ magical ” — at least on the surface . \\n the reality is they are syntactic sugar on top of functions with recursive switch statements where each case is a yield point . \\n they aren’t that hard to grok — the syntax is mind bending . having code that looks synchronous but behaves asynchronous is “ magical . ” \\n i think it does come down to that because everyone loves async / await even tho that ’s just sugar on generators where each yield must be a promise . \\n personally , i love redux - saga . it took me a little while to wrap my head around it ( but 1/10th the amount of time as rxjs ) , but it is _ really _ nice to be able to write complex async logic in synchronous - looking code that 's also readable . ( at least it was readable for me and the people on my team . ) whenever i had some weird async coordination problem that i needed to solve , i was _ always _ able to solve it with redux - saga . i wish more people would use it . \\n i feel the same way which is why i decided to help maintain the project . async flow control is very tricky even in js–land . having watchers live inside of a while - loop is a powerful construct that lends itself to interest flow control patterns . \\n i 'm also in the process of rebuilding redux - saga but without the redux part : https : / / github . com / neuro snap / star fx \\n it 's still in alpha stage , but it is very reminiscent of redux - saga . \\n and then there 's async generators . . . \\n nothing other than they 're one of the more esoteric and misunderstood features of the language . \\n it ’s a great question , and for the folks who knows the answer of why generators misunderstood , they surely discovered this feature in the most unpleasant circumstances . \\n generators were introduced during javascript ’s awkward adolescence , where the cutting edge of es6 was only possible through babel ( which was then called 6 to 5 ) . they ’re fantastic for turning array like classes into iterable collections . but that ’s not what makes them bad . \\n for a time you had a perfect storm of javascript hell . promises were poly filled and rewritten as generators to take advantage of the ` yield ` keyword . you’ll most likely find out about this trick at the least opportune time : while debugging an async redux action . now every single stack trace is a high - stakes game of “ detangle the christmas lights ! \\n this was truly a horrible time to be a front end developer . not only did you have to transpile your code , you had to debug it through a source map wrung through webpack ’s module system . and while you ’re picking through this mud ball of a web app , there ’s a super senior software engineer giving a talk on the virtues of observable data management ! \\n i ’ve always suspected that these galaxy brain engineers are more like window washers on an ivory tower . and as for the rest of us , we ’re just the code gnomes who are shrug when given triangular bricks until told how round bricks are actually better . \\n i know this is all hyperbole but the emotion is real . for every productive hour of work gained through a new and necessary features , engineers have lost 10-fold on the lesser well - thought out javascript . i ’m not so sure that native observables will be any different . \\n is this an issue with observables or an issue with rxjs allowing you to shoot yourself in the foot ? \\n a saner api ( as shown in the proposal ) has some obvious benefits in handling certain use cases without necessarily devolving into the crazy streams one sees with rxjs . \\n i 've never understood why redux gets implemented so badly . . . i feel that the folks who build wacky redux implementations would still write spaghetti managing state without redux . \\n the biggest issue is that for the first few years there was no single standardized way to write redux code . everyone came up with their own patterns , and wrote their own helper libraries . it also required a lot of \\\" boilerplate \\\" code for things like defining action type strings , action creator functions , and hand - written immutable updates . \\n that 's why we published our official redux toolkit package in 2019 . it standardizes redux usage , and includes methods that build in our recommended approaches for things like store setup , writing reducers , simpler immutable updates with immer , and even a complete server data fetching and caching solution called rtk query : \\n - https : / / redux . js . org / introduction / why - rtk - is - redux - today \\n - https : / / redux . js . org / tutorials / essentials / part - 2 - app - struc tu . . . \\n we routinely get highly positive feedback from folks who hated writing old - style redux , but love using rtk . \\n related , we also have a \\\" style guide \\\" docs page that provides guidance on what approaches we recommend using when writing redux code : \\n - https : / / redux . js . org / style - guide / \\n having used rtk and rtkq , i cannot believe they come from the same authors . rtk is mostly serviceable , though for most projects , not using redux is better . i ’ve never seen a case when rtkq was an improvement over fetch ( ) . \\n obviously , deleting redux from the internet to prevent incompetent engineering leads / managers from forcing it on people would be preferable . \\n if you can't understand the benefits of using rtk query over fetch i 'm not sure you 're credible . \\n they 're not even substitutes ; rtk query by default wraps fetch or can be configured to use your preferred http client . so it 's an entirely additional layer of cacheing and refetching logic with a standardized interface around common loading and error states . \\n it is considerably easier to write performant web applications with a library like rtk query or tanstack query than to just use fetch and try to roll your own cacheing solution . i say this as someone who has done all of the above professionally . \\n in my experience it was due to backend devs ( like myself ) being asked to or volunteering for some front end projects . at least that is how our current front end turned into a redux mess and is currently being rewritten . \\n it is a completely different skillset and i think more often than not people assume that they can write front end code just because they know javascript . \\n redux is very straightforward until you start adding middleware , then the complexities start piling up . \\n i am a nuts and bolts python programmer . what the heck even is this ? \\n why not have it return an async iterable , which has both push and pull semantics ? combined with the iterable helpers proposal you 'd get a lot of things for free , including end - to - end back pressure . \\n shouldn't this just be like a two line utility function to turn a add event listner call into an async iterable ? \\n lol first thing i did was ctrl + f for async iterator \\n my \\\" observation \\\" about observability and \\\" reactive type \\\" of code is that old school proxies , events and ways of defining expressions that get computed when the dependecies change is a much simpler way of programm reactive uis ( for example mvvm style of architectures ) compared with a functional programming approach . of course the naive approch does not work properly because any change in dependent values will trigger undesired side effects , reen trace , infinite loops , etc. however in a programming language like javascript if the observability is based on a sound pubsub system these kind of problems reduce to becoming surpin singly irelevant . if you want to undestand more about this , take a look on https : / / github . com / open dsu / sound pubsub / we used this approach to implement two ways binding and reactive mvvm web frameworks but this comment is to present this insight that it is possible to have a \\\" procedural \\\" and \\\" spreadsheet like \\\" method of implementing intuitive and sound rectivity without bending your mind with streams or anything very abstract . in a low code environment this could be essential . \\n some context about the current status : https : / / twitter . com / dom farolino / status / 1684921351004430336 \\n i only skimmed the document but i didn't see any mention of glitches . if this hasn't been addressed i 'm worried there hasn't been sufficient thought about the semantics of observables . glitches , and avoiding them in push systems , is addressed in flapjax ( 2009 ) : https : / / www . flapjax - lang . org / publications / \\n i also don't see why this needs to be part of javascript when it can be adequately implemented in a library . today 's great idea is tomorrow 's legacy . \\n what are glitches ? \\n glitches are transient incorrect values due to delays in propagating values . imagine a diamond pattern of reactive values like : \\n a = 0 , 1, 2, ... \\n b = a \\n c = a \\n d = b + c \\n d should be 0 , 2, 4 , ... but if , say , b updates and d sees this update before c updates then you can get incorrect values in d. \\n quite interesting . how does one resolve this ? \\n naive me would have d observe a and recalculate its value by recomputing b and c then . \\n other naive but complexity indulging me would store a dependency graph and use this graph to determine when one should wait for a value to update . \\n surely there must be an easier way ? \\n the key is topological sorting of a dependency graph . this can be done implicitly by storing a reactive variable node ’s depth once it is created , and just making sure that updates are enqueued in separate queues per depth . \\n i have a somewhat small implementation that transparently batches updates with queuemicrotask in this library ( bruh ) : https : / / github . com / technical - source / bruh / blob / a 829 af 9 df 9405 b . . . \\n they used to track a dependency map explicitly so they can determine when your “ transaction ” begins and ends so you can update all dirty at once . \\n another way to deal with it is explicitly not dealing with it , eg . saying it is only ( inconsistent ) ui and will go away in a millisec … \\n if b , c , and d were lazily evaluated ( pull - based ) you would also avoid this issue , \\n how does it differ from < https : / / github . com / tc 39 / proposal - observable / > ? \\n what exactly will this benefit from ? \\n which programming language and / or platform ? is it too obvious to mention it ? \\n ecmascript i have to assume \\n tc39 ( the js standards body ) and whatwg ( the web standards body ) have been ping - ponging this back and forth between one another . \\n i believe whatwg is being favored so observables will have a \\\" killer app \\\" ( events ) and could hence be built into the platform . as i recall , there was friction in tc39 to the effect of \\\" rxjs exists . why bother specifying this in the language ? \\\" \\n > \\\" rxjs exists . why bother specifying this in the language ? \\\" \\n and , honestly , that 's a great point . it 's even easy to wrap event targets : from event ( target , ' event name ' ) . \\n for the record : i 'm a big fan of rxjs and have used it in production client - side code for several years . but even i 'm not hot on this proposal to build it into the language . \\n js does not need observable api , it already had async iterables that soon will be enhanced with these helpers https : / / github . com / tc 39 / proposal - async - iterator - helpers that are similar to this proposal \\n i like this ! \\n would absolutely love this .\",\"datePublished\":null,\"dateLastCrawled\":null}],\"someResultsRemoved\":true}}}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "\n",
    "url = \"https://api.langsearch.com/v1/web-search\"\n",
    "\n",
    "payload = json.dumps({\n",
    "  \"query\": \"Tell me about the compant KnotAPI in detail\",\n",
    "  \"freshness\": \"noLimit\",\n",
    "  \"summary\": True,\n",
    "  \"count\": 10\n",
    "})\n",
    "headers = {\n",
    "  'Authorization': f'Bearer {key}',\n",
    "  'Content-Type': 'application/json'\n",
    "}\n",
    "\n",
    "response = requests.request(\"POST\", url, headers=headers, data=payload)\n",
    "\n",
    "print(response.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec8be042",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Config:\n",
    "    BASE_URL = \"https://api.langsearch.com/v1/web-search\"\n",
    "    API_KEY = os.getenv(\"LANGSEARCH_API_KEY\")\n",
    "    DB_PATH = \"search_cache.json\"\n",
    "    count = 10\n",
    "    freshness = \"noLimit\"\n",
    "    summary = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "f06fea5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "from tinydb import TinyDB, Query\n",
    "from IPython.display import display, Markdown\n",
    "from textwrap import shorten\n",
    "from urllib.parse import urlparse\n",
    "\n",
    "DEFAULT_BASE_URL = Config.BASE_URL\n",
    "DEFAULT_DB_PATH  = Config.DB_PATH\n",
    "\n",
    "\n",
    "def _safe(s: str | None, fallback: str = \"\") -> str:\n",
    "    return (s or fallback).strip()\n",
    "\n",
    "\n",
    "def _pretty_host(u: str | None) -> str:\n",
    "    if not u:\n",
    "        return \"\"\n",
    "    try:\n",
    "        host = urlparse(u).netloc\n",
    "        return host.replace(\"www.\", \"\")\n",
    "    except Exception:\n",
    "        return \"\"\n",
    "\n",
    "\n",
    "class LangSearchClient:\n",
    "    def __init__(self, api_key: str, db_path: str = DEFAULT_DB_PATH, endpoint: str | None = DEFAULT_BASE_URL):\n",
    "        \"\"\"\n",
    "        Initialize client with API key, TinyDB path, and optional endpoint override.\n",
    "        \"\"\"\n",
    "        if endpoint is None:\n",
    "            raise ValueError(\"Missing BASE_URL. Pass endpoint=... or define Config.BASE_URL.\")\n",
    "        self.api_key = api_key\n",
    "        self.db = TinyDB(db_path)\n",
    "        self.endpoint = endpoint\n",
    "\n",
    "    def search(self, query: str, count: int = 10, freshness: str = \"noLimit\", summary: bool = True):\n",
    "        payload = {\n",
    "            \"query\": query,\n",
    "            \"count\": count,\n",
    "            \"freshness\": freshness,\n",
    "            \"summary\": summary,\n",
    "        }\n",
    "        headers = {\n",
    "            \"Authorization\": f\"Bearer {self.api_key}\",\n",
    "            \"Content-Type\": \"application/json\",\n",
    "        }\n",
    "\n",
    "        r = requests.post(self.endpoint, headers=headers, json=payload, timeout=45)\n",
    "        if r.status_code != 200:\n",
    "            raise RuntimeError(f\"API error {r.status_code}: {r.text}\")\n",
    "\n",
    "        data = r.json()\n",
    "        results = data.get(\"data\", {}).get(\"webPages\", {}).get(\"value\", []) or []\n",
    "        if not results:\n",
    "            print(\"No results found.\")\n",
    "            return []\n",
    "\n",
    "        entries = []\n",
    "        for res in results:\n",
    "            record = {\n",
    "                \"query\": query,\n",
    "                \"name\": _safe(res.get(\"name\"), \"Untitled Result\"),\n",
    "                \"url\": _safe(res.get(\"url\")),\n",
    "                \"displayUrl\": _safe(res.get(\"displayUrl\"), _safe(res.get(\"url\"))),\n",
    "                \"snippet\": _safe(res.get(\"snippet\")),\n",
    "                \"summary\": _safe(res.get(\"summary\")),\n",
    "            }\n",
    "            self.db.insert(record)\n",
    "            entries.append(record)\n",
    "\n",
    "        print(f\"Stored {len(entries)} results for '{query}'\")\n",
    "        return entries\n",
    "\n",
    "    # --- DROP-IN REPLACEMENT STARTS HERE ---\n",
    "    def display_results(self, query: str, limit: int = 10, show_snippet: bool = True, show_summary: bool = True):\n",
    "        \"\"\"\n",
    "        Display stored search results in clean, structured Markdown.\n",
    "        - Renders once (no duplicate prints)\n",
    "        - Handles empty fields gracefully\n",
    "        - Truncates very long summaries\n",
    "        \"\"\"\n",
    "        Q = Query()\n",
    "        rows = self.db.search(Q.query == query)\n",
    "        if not rows:\n",
    "            print(f\"No stored results found for '{query}'.\")\n",
    "            return\n",
    "\n",
    "        # Stable ordering: by name then url; apply limit\n",
    "        rows = sorted(rows, key=lambda r: (r.get(\"name\") or \"\", r.get(\"url\") or \"\"))[:limit]\n",
    "\n",
    "        md = []\n",
    "        md.append(f\"# 🔍 Results for **{query}**\")\n",
    "        md.append(\"\")\n",
    "        md.append(f\"*Showing {len(rows)} stored result(s).*\")\n",
    "        md.append(\"\")\n",
    "\n",
    "        for i, r in enumerate(rows, 1):\n",
    "            title = _safe(r.get(\"name\"), \"Untitled Result\")\n",
    "            url = _safe(r.get(\"url\"))\n",
    "            durl = _safe(r.get(\"displayUrl\"), url)\n",
    "            host = _pretty_host(url)\n",
    "            snippet = _safe(r.get(\"snippet\"))\n",
    "            summary = _safe(r.get(\"summary\"))\n",
    "\n",
    "\n",
    "            # Card header\n",
    "            md.append(f\"---\")\n",
    "            md.append(f\"### {i}. [{title}]({url})\")\n",
    "            if host:\n",
    "                md.append(f\"*{host}*  \")\n",
    "            else:\n",
    "                md.append(\"\")\n",
    "\n",
    "            # Link row\n",
    "            if url:\n",
    "                md.append(f\"**🌐 URL:** [{durl}]({url})\")\n",
    "            else:\n",
    "                md.append(\"**🌐 URL:** _(missing)_\")\n",
    "\n",
    "            # Optional snippet\n",
    "            if show_snippet and snippet:\n",
    "                md.append(\"\")\n",
    "                md.append(\"**Snippet**\")\n",
    "                md.append(f\"> {snippet}\")\n",
    "\n",
    "            # Optional summary\n",
    "            if show_summary and summary:\n",
    "                md.append(\"\")\n",
    "                md.append(\"**Summary**\")\n",
    "                md.append(f\"> {summary}\")\n",
    "\n",
    "            md.append(\"\")  # space after each card\n",
    "\n",
    "        # Render once\n",
    "        display(Markdown(\"\\n\".join(md)))\n",
    "    # --- DROP-IN REPLACEMENT ENDS HERE ---\n",
    "\n",
    "    def clear(self):\n",
    "        self.db.truncate()\n",
    "        print(\"🧹 Database cleared.\")\n",
    "\n",
    "    def list_queries(self):\n",
    "        return sorted({r.get(\"query\") for r in self.db.all() if r.get(\"query\")})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ee0fc889",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored 10 results for 'https://www.airops.com/'\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "# 🔍 Results for **https://www.airops.com/**\n",
       "\n",
       "*Showing 10 stored result(s).*\n",
       "\n",
       "---\n",
       "### 1. [AVIAREPS UK | LinkedIn](https://es.linkedin.com/company/aviareps-uk?trk=ppro_cprof)\n",
       "*es.linkedin.com*  \n",
       "**🌐 URL:** [https://es.linkedin.com/company/aviareps-uk?trk=ppro_cprof](https://es.linkedin.com/company/aviareps-uk?trk=ppro_cprof)\n",
       "\n",
       "**Snippet**\n",
       "> aviareps uk \n",
       " organización de viajes \n",
       " london , england 3047 seguidores \n",
       " leading general sales agent in aviation , hospitality , tourism , pr and events \n",
       " sobre nosotros \n",
       " with our brand new office l...\n",
       "\n",
       "**Summary**\n",
       "> aviareps uk \n",
       " organización de viajes \n",
       " london , england 3047 seguidores \n",
       " leading general sales agent in aviation , hospitality , tourism , pr and events \n",
       " sobre nosotros \n",
       " with our brand new office locations in london and dublin , our small , but highly dedicated team , brings to our aviation and tourism partners an individually tailor-made and passionate approach . combined with our deep understanding of the travel industry it is our vision to grow your business and connect the world . part of the aviareps ag family , aviareps uk is a multi - award - winning full service representation company made up of four specialist departments : tourism sales & marketing , media communications , events & project management and aviation sales & marketing . leveraging our expertise across these four specialist divisions both in the uk and through our global aviareps network , we provide focused full-service representation . our mission : to introduce and connect tourism and aviation products to local markets and provide people with a deeper understanding of foreign cultures , destinations and ways on how to get there . in addition , this commitment helps us to bring people to the world by creating brand awareness and arising the wish to travel to foreign spots , to take advantage of the best airline services and help our clients generate more travel volume . our vision : to grow your business tourism clients we have worked with include ontario tourism , palm beach county convention and visitors bureau , turismo chile , chic outlet shopping , aqua & aston hotels , experience latin america , formentera , costa rica , the basque country and hamburg tourist board . some of our aviation clients include caribbean airlines , miat , surinam airways , ukraine international , gulf air , air astana , air madagascar , air botswana , amongst many others . \n",
       " sitio web \n",
       " http : / / www . aviareps . com \n",
       " sector \n",
       " organización de viajes \n",
       " tamaño de la empresa \n",
       " de 11 a 50 empleados \n",
       " sede \n",
       " london , england \n",
       " tipo \n",
       " de financiación privada \n",
       " fundación \n",
       " 2001 \n",
       " especialidades \n",
       " tourism marketing , tourism pr , tourism representation , aviation gsa , tourism & aviation events , media communications , public relations , aviation marketing , project management , airline representation y general sales agent \n",
       " ubicaciones \n",
       " principal \n",
       " 77 fulham palace road \n",
       " w6 8ja \n",
       " london , england , gb \n",
       " empleados en aviareps uk \n",
       " james harrison \n",
       " aviation | commercial leadership | … \n",
       " emma mcenroe \n",
       " pr manager aviareps uk \n",
       " martin court \n",
       " tourism & business development … \n",
       " karen etherington \n",
       " european regional account manager at … \n",
       " actualizaciones \n",
       " escape to a seaside holiday in lithuania and find your inner bliss in the heaven of sun , sea and the sand . thank you bradt guides for another captivating feature about lovely lithuania . lithuania travel # aviareps uk # travel pr \n",
       " the best beaches in lithuania for you to visit \n",
       " https : / / www . bradt guides . com \n",
       " when in zadar region , bite into the natural larder nestled in a tapestry of landscapes and find your own gourmet adventure .   before your tasty departure , reward your taste buds with wanderlust travel media features , also containing mary novakovich ’s delectable discoveries . thank you very much mihaela kadija and branka martinec of the zadar regional tourist board for a rewarding collaboration . # zadar _ region # say yes to everything # croatia full of life # wanderlust magazine # wanderlust mag # aviareps uk # travel pr \n",
       " a gastronomy guide to zadar - wanderlust \n",
       " https : / / www . wanderlust magazine . com \n",
       " aviareps uk was both honoured and delighted to welcome top - tier journalists and agents in tast catala restaurant for the press lunch and presentation hosted by costa brava girona tourist board . thank you anna cuadrat and the team for the most valuable collaboration , paired with costa brava 's food and wine excellence artfully customized by the 5-star michelin chef , paco pérez . # in costa brava # in pyrenees # # costa brava excellence # aviareps uk # travel pr   \n",
       " have you got a minute to spare ? spend it in # zadar _ region and find a zillion reasons to visit . thank you , wanderlust travel media , mihaela kadija , director of zadar regional tourist board and @ zadar _ region team for a sparkling collaboration . # say yes to zadarregion # say yes to everything # croatia full of life # aviareps uk \n",
       " find your own adventure in zadar \n",
       " https : / / www . youtube . com / \n",
       " experience in tourism , hotels , tourism marketing , or pr ?   searching for a new challenge ? look no further , because at aviareps uk we are looking for a tourism business development manager in london ( hybrid ) .   for this position , a relevant network is key ! check the link below for more details : https : / / lnkd . in / e uk cy 9 fy # tourism # hotel # marketing # pr aviareps group \n",
       " aviareps uk and the croatian national tourist board hosted tristan rutherford in # croatia , which resulted in a dream - come true # cover story , a four - page spread in the sunday times , and online travel article , featuring adriatic extravaganza , also enriched with the video content . thank you so much laura jackson and tristan for an incredible collaboration , and for showcasing slow - travel bliss of rijeka , opatija , and the # kvarner region . # croatia full of life # aviareps uk # travel pr . \n",
       " one train , three countries and a £ 7 ticket : europe ’s newest rail trip \n",
       " the times . co . uk \n",
       " aviareps uk hosted five incredible journalists from the # uk at the croatian national tourist board 's 20th golden pen media awards in dubrovnik and dubrovnik - neretva region from 7 - 10 may . adrian chiles , elise tanriverdi , mary novakovich , phoebe nicolaou , and rick jordan have been recognized for their invaluable media contribution in promoting croatia . the alluring awards programme couldn't have been achieved without the organisation and the attention to detail by the team of the croatian national tourist board . thank you all once again # croatia full of life , dubrovnik tourist board dubrovnik & neretva county tourist board . # aviareps uk # travel pr \n",
       " aviareps uk thoroughly enjoyed in creating an interview opportunity for nikolina brnjac , minister of tourism and sports of the republic of croatia , who shared her thoughts , hopes and plans with saskia o'donoghue of the euronews . find out more about croatia , and how this incredible destination is paving the way in becoming one of the most sustainable travel destinations in europe . # aviareps uk # travel pr # croatia full of life \n",
       " could croatia be the most sustainable travel destination in europe ? \n",
       " euronews . com \n",
       " who would have thought that a small country in the baltic states could hide so many beautiful castles ? known by some as the ‘ land of castles ’ , lithuania was once a place where knights and princesses roamed . . . ⁠ discover more within the latest bradt guides unveiling a piece of lithuania fit for royalty . ⁠   lithuania travel , bradt guides , ingrida dar aš aitė , # aviareps uk # travel pr \n",
       " the most interesting castles in lithuania for you to visit \n",
       " https : / / www . bradt guides . com\n",
       "\n",
       "---\n",
       "### 2. [Aero Solutions LLC. | LinkedIn](https://pt.linkedin.com/company/aero-solutions-llc.)\n",
       "*pt.linkedin.com*  \n",
       "**🌐 URL:** [https://pt.linkedin.com/company/aero-solutions-llc.](https://pt.linkedin.com/company/aero-solutions-llc.)\n",
       "\n",
       "**Snippet**\n",
       "> aero solutions llc . \n",
       " télécommunications \n",
       " broomfield , colorado 1 614 abonnés \n",
       " à propos \n",
       " aero solutions llc is a leader in the wireless infrastructure industry , developing state - of - the - art ...\n",
       "\n",
       "**Summary**\n",
       "> aero solutions llc . \n",
       " télécommunications \n",
       " broomfield , colorado 1 614 abonnés \n",
       " à propos \n",
       " aero solutions llc is a leader in the wireless infrastructure industry , developing state - of - the - art solutions for macrocell and small cell deployments . the company ’s team of experienced professional engineers focus on delivering cost - effective solutions for our clients . we are nationally recognized for innovative , reliable , and safe infrastructure products required to achieve quality installations . \n",
       " site web \n",
       " aerosolutions llc . com \n",
       " secteur \n",
       " télécommunications \n",
       " taille de l’entreprise \n",
       " 2 - 10 employés \n",
       " siège social \n",
       " broomfield , colorado \n",
       " type \n",
       " société civile / société commerciale / autres types de sociétés \n",
       " fondée en \n",
       " 2004 \n",
       " domaines \n",
       " telecommunication tower reinforcement , engineering design with aerosoft , telecommunication tower mapping et telecommunication tower inspection \n",
       " lieux \n",
       " principal \n",
       " 11001 w 120th ave \n",
       " # 400 \n",
       " 80021 broomfield , colorado , us \n",
       " 738 peoria st - po box 31164 \n",
       " ste d \n",
       " 80011 aurora , co , us \n",
       " employés chez aero solutions llc . \n",
       " kevin dahlin \n",
       " ceo armor works enterprises inc. \n",
       " bruce offutt \n",
       " chief financial officer \n",
       " birney kirkpatrick \n",
       " sales and r&d at 3 d solutions \n",
       " ryan hardman \n",
       " cad designer at aero solutions llc .\n",
       "\n",
       "---\n",
       "### 3. [AirOps](https://marketplace.aiia.tech/items/airops)\n",
       "*marketplace.aiia.tech*  \n",
       "**🌐 URL:** [https://marketplace.aiia.tech/items/airops](https://marketplace.aiia.tech/items/airops)\n",
       "\n",
       "**Snippet**\n",
       "> airops \n",
       " about this app \n",
       " airops is a collection of configurable , task - specific ai apps with superpowers . with airops you can : 1. draft , fix , and optimize sql queries with natural language . 2....\n",
       "\n",
       "**Summary**\n",
       "> airops \n",
       " about this app \n",
       " airops is a collection of configurable , task - specific ai apps with superpowers . with airops you can : 1. draft , fix , and optimize sql queries with natural language . 2. perform nlp techniques like text classification , sentiment analysis , and entity extraction at scale , without the need for training data or technical resources . 3. generate personalized content with context from your data warehouse , the web , or any api . 4 . turn any file type ( video , audio , pdf , text ) into rich summaries or net new asset types ( e . g . , landing pages , emails , blog posts ) \n",
       " unknown \n",
       " type : \n",
       " social links : \n",
       " writing assistant \n",
       " text and written content\n",
       "\n",
       "---\n",
       "### 4. [AirOps Introduction](https://tyy.ai/airops/introduction/)\n",
       "*tyy.ai*  \n",
       "**🌐 URL:** [https://tyy.ai/airops/introduction/](https://tyy.ai/airops/introduction/)\n",
       "\n",
       "**Snippet**\n",
       "> airops introduction \n",
       " airops introduction . airops is a platform that allows businesses to create , test , deploy , and scale ai apps using airops studio . with powerful tools and workflows , airops b...\n",
       "\n",
       "**Summary**\n",
       "> airops introduction \n",
       " airops introduction . airops is a platform that allows businesses to create , test , deploy , and scale ai apps using airops studio . with powerful tools and workflows , airops brings ai to important processes , enabling users to design and launch workflows and agents using the latest language models like gpt-4 32 k and claude 2. \n",
       " what is air ops ? \n",
       " airops is a platform that allows businesses to create , test , deploy , and scale ai apps using airops studio . with powerful tools and workflows , airops brings ai to important processes , enabling users to design and launch workflows and agents using the latest language models like gpt-4 32 k and claude 2. \n",
       " how to use air ops ? \n",
       " to use air ops , start by signing up for an account and accessing airops studio . from there , you can create ai apps by combining language models , data , python , javascript , and external apis . you can use the templates provided to jumpstart your app development or customize your own workflows and chat agents . once your app is built , you can deploy it to your team or customers via integrations and apis . airops also offers features like versioning , evaluations , and logs to manage and monitor your app 's performance .\n",
       "\n",
       "---\n",
       "### 5. [AirX inc. AIROS Skyview | Fournisseur GetYourGuide](https://www.getyourguide.fr/airx-inc-airos-skyview-s19141/)\n",
       "*getyourguide.fr*  \n",
       "**🌐 URL:** [https://www.getyourguide.fr/airx-inc-airos-skyview-s19141/](https://www.getyourguide.fr/airx-inc-airos-skyview-s19141/)\n",
       "\n",
       "**Snippet**\n",
       "> airx inc. airos skyview \n",
       " cet organisateur d ’ activité offre ses services sur la plateforme getyourguide \n",
       " mentions légales \n",
       " nom légal de l’entreprise \n",
       " airx inc. \n",
       " adresse \n",
       " 718 12 shinjuku buildin...\n",
       "\n",
       "**Summary**\n",
       "> airx inc. airos skyview \n",
       " cet organisateur d ’ activité offre ses services sur la plateforme getyourguide \n",
       " mentions légales \n",
       " nom légal de l’entreprise \n",
       " airx inc. \n",
       " adresse \n",
       " 718 12 shinjuku building 160 - 0023 shinjuku - ku tokyo \n",
       " direction \n",
       " kiwamu tezuka \n",
       " numéro d’entreprise \n",
       " t5020001109791 \n",
       " coordonnées \n",
       " à propos de l ’ organisateur d ’ activité \n",
       " take in the sights from the vantage point of your personal helicopter . airx boasts an impressive network of aviation companies across japan , allowing for travellers through all regions a chance to take a bespoke tour across the skies . explore tokyo ’s futuristic lights , kyoto ’s storied heritage and any number of japanese cities , all from a spectacular bird ’s eye view .\n",
       "\n",
       "---\n",
       "### 6. [Empeiros66 | LinkedIn](https://ae.linkedin.com/company/empeiros66?trk=similar-pages)\n",
       "*ae.linkedin.com*  \n",
       "**🌐 URL:** [https://ae.linkedin.com/company/empeiros66?trk=similar-pages](https://ae.linkedin.com/company/empeiros66?trk=similar-pages)\n",
       "\n",
       "**Snippet**\n",
       "> empeiros66 \n",
       " الخطوط الجوية والطيران \n",
       " interactive e-books for easa part 66 basic aircraft maintenance training \n",
       " نبذة عنا \n",
       " interactive e-books for your basic aircraft maintenance training \n",
       " الموقع ال...\n",
       "\n",
       "**Summary**\n",
       "> empeiros66 \n",
       " الخطوط الجوية والطيران \n",
       " interactive e-books for easa part 66 basic aircraft maintenance training \n",
       " نبذة عنا \n",
       " interactive e-books for your basic aircraft maintenance training \n",
       " الموقع الإلكتروني \n",
       " https : / / www . em peiros 66 . com \n",
       " رابط خارجي لـ empeiros66 \n",
       " المجال المهني \n",
       " الخطوط الجوية والطيران \n",
       " حجم الشركة \n",
       " ٥١ - ٢٠٠ من الموظفين \n",
       " المقر الرئيسي \n",
       " worldwide \n",
       " النوع \n",
       " شركة يملكها عدد قليل من الأشخاص \n",
       " المواقع الجغرافية \n",
       " رئيسي \n",
       " worldwide ، ae \n",
       " احصل على اتجاهات السير \n",
       " التحديثات \n",
       " easa is set to introduce revisions to part-147 to address fraud risks in maintenance training , aiming to bolster safety and credibility . key takeaways from these proposed revisions include : - fraud mitigation : targeting a reduction in cheating during examinations , particularly outside approved locations . - language proficiency : ensuring effective training through language comprehension . - management system : clarifying responsibilities and qualifications for personnel . - compliance measures : strengthening monitoring and examination security . - location restrictions : restricting training activities to approved locations . anticipated outcomes include a decrease in fraud and long - term improvement in maintenance competence . cheers to progress in the skies ! # easa # maintenance training # aviati onsafety # aircraft maintenance https : / / lnkd . in / gdc xs vfz \n",
       " easa bids to reduce maintenance fraud risk by revising training framework \n",
       " flight global . com \n",
       " empeiros interactive e-books are a worthwhile upgrade compared to ordinary e-books and study materials . with em peiros . . . students can read . . . see engines and aircraft systems in action . . . . and virtually practice usage of tools and equipment . choose empeiros for better theoretical understanding and practical skills preparedness ! # aircraft maintenance   # easa part 66   # mro   #   # aircraft   # aviation training   # aviation training center   # ebooks   # interactive ebooks   # simulation training   # technology \n",
       " aircraft maintenance engineers play a crucial role in the smooth operation and safety of flights . however , they often face challenges in obtaining experience using tools and equipment and practicing maintenance procedures during their basic training . these limitations can stem from a lack of access to the necessary resources and a shortage of time allocated for such training events . fortunately , empeiros interactive e-books have emerged as an innovative solution aimed at addressing these challenges . by providing trainees with virtual experiences , empeiros empowers them to gain valuable experience with a diverse range of tools , equipment , and procedures at their own pace and convenience . this cutting - edge approach not only facilitates effective basic training but also significantly enhances the preparedness of trainees for their future roles . empeiros stands as a testament to the progress made in the field of aircraft maintenance training ! visit our website for more information https : / / lnkd . in / dyq deur # easa # easa 66 # aircraft maintenance # aircraft mechanic \n",
       " empeiros is a next - generation electronic textbook platform that conveys the entire easa part 66 syllabus in the best possible way for aircraft maintenance trainees to learn and comprehend easily . visit our website for demo   www . em peiros 66 . com # aircraft maintenance   # aviation training   # aviation industry   # ebooks   # easa part 66   # easa   # aircraft maintenance   # training and development\n",
       "\n",
       "---\n",
       "### 7. [List of Apple's mobile device codes types a.k.a. machine ids (e.g. `iPhone1,1`, `Watch1,1`, etc.) and their matching product names · GitHub](https://gist.github.com/adamawolf/3048717?permalink_comment_id=5233393)\n",
       "*gist.github.com*  \n",
       "**🌐 URL:** [https://gist.github.com/adamawolf/3048717?permalink_comment_id=5233393](https://gist.github.com/adamawolf/3048717?permalink_comment_id=5233393)\n",
       "\n",
       "**Snippet**\n",
       "> adama wolf / apple _ mobile _ device _ types . txt \n",
       " list of apple 's mobile device codes types a.k.a. machine ids ( e . g . ` iphone 1 , 1 ` , ` watch 1 , 1 ` , etc . ) and their matching product nam...\n",
       "\n",
       "**Summary**\n",
       "> adama wolf / apple _ mobile _ device _ types . txt \n",
       " list of apple 's mobile device codes types a.k.a. machine ids ( e . g . ` iphone 1 , 1 ` , ` watch 1 , 1 ` , etc . ) and their matching product names \n",
       " raw \n",
       " apple _ mobile _ device _ types . txt \n",
       " i386 : iphone simulator \n",
       " x86_64 : iphone simulator \n",
       " arm64 : iphone simulator \n",
       " iphone 1 , 1 : iphone \n",
       " iphone 1 , 2 : iphone 3 g \n",
       " iphone 2 , 1 : iphone 3gs \n",
       " iphone 3 , 1 : iphone 4 \n",
       " iphone 3 , 2 : iphone 4 gsm rev a \n",
       " iphone 3 , 3 : iphone 4 cdma \n",
       " iphone 4 , 1 : iphone 4s \n",
       " iphone 5 , 1 : iphone 5 ( gsm ) \n",
       " iphone 5 , 2 : iphone 5 ( gsm + cdma ) \n",
       " iphone 5 , 3 : iphone 5c ( gsm ) \n",
       " iphone 5 , 4 : iphone 5c ( global ) \n",
       " iphone 6 , 1 : iphone 5s ( gsm ) \n",
       " iphone 6 , 2 : iphone 5s ( global ) \n",
       " iphone 7 , 1 : iphone 6 plus \n",
       " iphone 7 , 2 : iphone 6 \n",
       " iphone8,1 : iphone 6s \n",
       " iphone 8 , 2 : iphone 6s plus \n",
       " iphone 8 , 4 : iphone se ( gsm ) \n",
       " iphone9,1 : iphone 7 \n",
       " iphone 9 , 2 : iphone 7 plus \n",
       " iphone 9 , 3 : iphone 7 \n",
       " iphone 9 , 4 : iphone 7 plus \n",
       " iphone 10 , 1 : iphone 8 \n",
       " iphone 10 , 2 : iphone 8 plus \n",
       " iphone 10 , 3 : iphone x global \n",
       " iphone10,4 : iphone 8 \n",
       " iphone 10 , 5 : iphone 8 plus \n",
       " iphone10,6 : iphone x gsm \n",
       " iphone 11 , 2 : iphone xs \n",
       " iphone 11 , 4 : iphone xs max \n",
       " iphone 11 , 6 : iphone xs max global \n",
       " iphone 11 , 8 : iphone xr \n",
       " iphone 12 , 1 : iphone 11 \n",
       " iphone 12 , 3 : iphone 11 pro \n",
       " iphone 12 , 5 : iphone 11 pro max \n",
       " iphone 12 , 8 : iphone se 2nd gen \n",
       " iphone 13 , 1 : iphone 12 mini \n",
       " iphone 13 , 2 : iphone 12 \n",
       " iphone 13 , 3 : iphone 12 pro \n",
       " iphone 13 , 4 : iphone 12 pro max \n",
       " iphone 14 , 2 : iphone 13 pro \n",
       " iphone 14 , 3 : iphone 13 pro max \n",
       " iphone 14 , 4 : iphone 13 mini \n",
       " iphone 14 , 5 : iphone 13 \n",
       " iphone 14 , 6 : iphone se 3rd gen \n",
       " iphone 14 , 7 : iphone 14 \n",
       " iphone 14 , 8 : iphone 14 plus \n",
       " iphone 15 , 2 : iphone 14 pro \n",
       " iphone 15 , 3 : iphone 14 pro max \n",
       " iphone 15 , 4 : iphone 15 \n",
       " iphone 15 , 5 : iphone 15 plus \n",
       " iphone 16 , 1 : iphone 15 pro \n",
       " iphone 16 , 2 : iphone 15 pro max \n",
       " iphone 17 , 1 : iphone 16 pro \n",
       " iphone 17 , 2 : iphone 16 pro max \n",
       " iphone 17 , 3 : iphone 16 \n",
       " iphone 17 , 4 : iphone 16 plus \n",
       " iphone 17 , 5 : iphone 16e \n",
       " iphone 18 , 1 : iphone 17 pro \n",
       " iphone 18 , 2 : iphone 17 pro max \n",
       " iphone 18 , 3 : iphone 17 \n",
       " iphone 18 , 4 : iphone air \n",
       " ipod 1 , 1 : 1st gen ipod \n",
       " ipod 2 , 1 : 2nd gen ipod \n",
       " ipod 3 , 1 : 3rd gen ipod \n",
       " ipod 4 , 1 : 4th gen ipod \n",
       " ipod 5 , 1 : 5th gen ipod \n",
       " ipod 7 , 1 : 6th gen ipod \n",
       " ipod 9 , 1 : 7th gen ipod \n",
       " ipad 1 , 1 : ipad \n",
       " ipad 1 , 2 : ipad 3 g \n",
       " ipad 2 , 1 : 2nd gen ipad \n",
       " ipad 2 , 2 : 2nd gen ipad gsm \n",
       " ipad 2 , 3 : 2nd gen ipad cdma \n",
       " ipad 2 , 4 : 2nd gen ipad new revision \n",
       " ipad 3 , 1 : 3rd gen ipad \n",
       " ipad 3 , 2 : 3rd gen ipad cdma \n",
       " ipad 3 , 3 : 3rd gen ipad gsm \n",
       " ipad2,5 : ipad mini \n",
       " ipad 2 , 6 : ipad mini gsm + lte \n",
       " ipad 2 , 7 : ipad mini cdma + lte \n",
       " ipad 3 , 4 : 4th gen ipad \n",
       " ipad 3 , 5 : 4th gen ipad gsm + lte \n",
       " ipad 3 , 6 : 4th gen ipad cdma + lte \n",
       " ipad 4 , 1 : ipad air ( wifi ) \n",
       " ipad 4 , 2 : ipad air ( gsm + cdma ) \n",
       " ipad 4 , 3 : 1st gen ipad air ( china ) \n",
       " ipad 4 , 4 : ipad mini retina ( wifi ) \n",
       " ipad 4 , 5 : ipad mini retina ( gsm + cdma ) \n",
       " ipad 4 , 6 : ipad mini retina ( china ) \n",
       " ipad 4 , 7 : ipad mini 3 ( wifi ) \n",
       " ipad 4 , 8 : ipad mini 3 ( gsm + cdma ) \n",
       " ipad 4 , 9 : ipad mini 3 ( china ) \n",
       " ipad 5 , 1 : ipad mini 4 ( wifi ) \n",
       " ipad 5 , 2 : ipad mini 4 ( wifi + cellular ) \n",
       " ipad 5 , 3 : ipad air 2 ( wifi ) \n",
       " ipad 5 , 4 : ipad air 2 ( cellular ) \n",
       " ipad 6 , 3 : ipad pro ( 9 . 7 inch , wifi ) \n",
       " ipad 6 , 4 : ipad pro ( 9 . 7 inch , wifi + lte ) \n",
       " ipad 6 , 7 : ipad pro ( 12 . 9 inch , wifi ) \n",
       " ipad6,8 : ipad pro ( 12 . 9 inch , wifi + lte ) \n",
       " ipad 6 , 11 : ipad ( 2017 ) \n",
       " ipad 6 , 12 : ipad ( 2017 ) \n",
       " ipad 7 , 1 : ipad pro 2nd gen ( wifi ) \n",
       " ipad 7 , 2 : ipad pro 2nd gen ( wifi + cellular ) \n",
       " ipad 7 , 3 : ipad pro 10.5-inch 2nd gen ( wifi ) \n",
       " ipad 7 , 4 : ipad pro 10.5-inch 2nd gen ( wifi + cellular ) \n",
       " ipad 7 , 5 : ipad 6th gen ( wifi ) \n",
       " ipad 7 , 6 : ipad 6th gen ( wifi + cellular ) \n",
       " ipad 7 , 11 : ipad 7th gen 10.2-inch ( wifi ) \n",
       " ipad 7 , 12 : ipad 7th gen 10.2-inch ( wifi + cellular ) \n",
       " ipad 8 , 1 : ipad pro 11 inch 3rd gen ( wifi ) \n",
       " ipad 8 , 2 : ipad pro 11 inch 3rd gen ( 1 tb , wifi ) \n",
       " ipad 8 , 3 : ipad pro 11 inch 3rd gen ( wifi + cellular ) \n",
       " ipad 8 , 4 : ipad pro 11 inch 3rd gen ( 1 tb , wifi + cellular ) \n",
       " ipad 8 , 5 : ipad pro 12.9 inch 3rd gen ( wifi ) \n",
       " ipad 8 , 6 : ipad pro 12.9 inch 3rd gen ( 1 tb , wifi ) \n",
       " ipad 8 , 7 : ipad pro 12.9 inch 3rd gen ( wifi + cellular ) \n",
       " ipad 8 , 8 : ipad pro 12.9 inch 3rd gen ( 1 tb , wifi + cellular ) \n",
       " ipad 8 , 9 : ipad pro 11 inch 4th gen ( wifi ) \n",
       " ipad 8 , 10 : ipad pro 11 inch 4th gen ( wifi + cellular ) \n",
       " ipad 8 , 11 : ipad pro 12.9 inch 4th gen ( wifi ) \n",
       " ipad 8 , 12 : ipad pro 12.9 inch 4th gen ( wifi + cellular ) \n",
       " ipad 11 , 1 : ipad mini 5th gen ( wifi ) \n",
       " ipad 11 , 2 : ipad mini 5th gen ( wifi + cellular ) \n",
       " ipad 11 , 3 : ipad air 3rd gen ( wifi ) \n",
       " ipad 11 , 4 : ipad air 3rd gen ( wifi + cellular ) \n",
       " ipad11,6 : ipad 8th gen ( wifi ) \n",
       " ipad 11 , 7 : ipad 8th gen ( wifi + cellular ) \n",
       " ipad 12 , 1 : ipad 9th gen ( wifi ) \n",
       " ipad 12 , 2 : ipad 9th gen ( wifi + cellular ) \n",
       " ipad 14 , 1 : ipad mini 6th gen ( wifi ) \n",
       " ipad 14 , 2 : ipad mini 6th gen ( wifi + cellular ) \n",
       " ipad13,1 : ipad air 4th gen ( wifi ) \n",
       " ipad 13 , 2 : ipad air 4th gen ( wifi + cellular ) \n",
       " ipad 13 , 4 : ipad pro 11 inch 5th gen \n",
       " ipad 13 , 5 : ipad pro 11 inch 5th gen \n",
       " ipad 13 , 6 : ipad pro 11 inch 5th gen \n",
       " ipad 13 , 7 : ipad pro 11 inch 5th gen \n",
       " ipad 13 , 8 : ipad pro 12.9 inch 5th gen \n",
       " ipad 13 , 9 : ipad pro 12.9 inch 5th gen \n",
       " ipad13,10 : ipad pro 12.9 inch 5th gen \n",
       " ipad13,11 : ipad pro 12.9 inch 5th gen \n",
       " ipad 13 , 16 : ipad air 5th gen ( wifi ) \n",
       " ipad 13 , 17 : ipad air 5th gen ( wifi + cellular ) \n",
       " ipad 13 , 18 : ipad 10th gen ( wifi ) \n",
       " ipad 13 , 19 : ipad 10th gen ( wifi + cellular ) \n",
       " ipad 14 , 3 : ipad pro 11 inch 4th gen ( wifi ) \n",
       " ipad 14 , 4 : ipad pro 11 inch 4th gen ( wifi + cellular ) \n",
       " ipad 14 , 5 : ipad pro 12.9 inch 6th gen ( wifi ) \n",
       " ipad 14 , 6 : ipad pro 12.9 inch 6th gen ( wifi + cellular ) \n",
       " ipad 14 , 8 : ipad air 11 inch 6th gen ( wifi ) \n",
       " ipad 14 , 9 : ipad air 11 inch 6th gen ( wifi + cellular ) \n",
       " ipad 14 , 10 : ipad air 13 inch 6th gen ( wifi ) \n",
       " ipad 14 , 11 : ipad air 13 inch 6th gen ( wifi + cellular ) \n",
       " ipad 15 , 3 : ipad air 11-inch 7th gen ( wifi ) \n",
       " ipad 15 , 4 : ipad air 11-inch 7th gen ( wifi + cellular ) \n",
       " ipad 15 , 5 : ipad air 13-inch 7th gen ( wifi ) \n",
       " ipad 15 , 6 : ipad air 13-inch 7th gen ( wifi + cellular ) \n",
       " ipad 15 , 7 : ipad 11th gen ( wifi ) \n",
       " ipad 15 , 8 : ipad 11th gen ( wifi + cellular ) \n",
       " ipad 16 , 1 : ipad mini 7th gen ( wifi ) \n",
       " ipad 16 , 2 : ipad mini 7th gen ( wifi + cellular ) \n",
       " ipad 16 , 3 : ipad pro 11 inch 5th gen ( wifi ) \n",
       " ipad 16 , 4 : ipad pro 11 inch 5th gen ( wifi + cellular ) \n",
       " ipad 16 , 5 : ipad pro 12.9 inch 7th gen ( wifi ) \n",
       " ipad 16 , 6 : ipad pro 12.9 inch 7th gen ( wifi + cellular ) \n",
       " watch 1 , 1 : apple watch 38 mm case \n",
       " watch 1 , 2 : apple watch 42 mm case \n",
       " watch 2 , 6 : apple watch series 1 38 mm case \n",
       " watch 2 , 7 : apple watch series 1 42 mm case \n",
       " watch 2 , 3 : apple watch series 2 38 mm case \n",
       " watch 2 , 4 : apple watch series 2 42 mm case \n",
       " watch 3 , 1 : apple watch series 3 38 mm case ( gps + cellular ) \n",
       " watch 3 , 2 : apple watch series 3 42 mm case ( gps + cellular ) \n",
       " watch 3 , 3 : apple watch series 3 38 mm case ( gps ) \n",
       " watch 3 , 4 : apple watch series 3 42 mm case ( gps ) \n",
       " watch 4 , 1 : apple watch series 4 40mm case ( gps ) \n",
       " watch 4 , 2 : apple watch series 4 44 mm case ( gps ) \n",
       " watch 4 , 3 : apple watch series 4 40mm case ( gps + cellular ) \n",
       " watch 4 , 4 : apple watch series 4 44 mm case ( gps + cellular ) \n",
       " watch 5 , 1 : apple watch series 5 40mm case ( gps ) \n",
       " watch 5 , 2 : apple watch series 5 44 mm case ( gps ) \n",
       " watch 5 , 3 : apple watch series 5 40mm case ( gps + cellular ) \n",
       " watch 5 , 4 : apple watch series 5 44 mm case ( gps + cellular ) \n",
       " watch 5 , 9 : apple watch se 40mm case ( gps ) \n",
       " watch 5 , 10 : apple watch se 44 mm case ( gps ) \n",
       " watch 5 , 11 : apple watch se 40mm case ( gps + cellular ) \n",
       " watch 5 , 12 : apple watch se 44 mm case ( gps + cellular ) \n",
       " watch 6 , 1 : apple watch series 6 40mm case ( gps ) \n",
       " watch 6 , 2 : apple watch series 6 44 mm case ( gps ) \n",
       " watch 6 , 3 : apple watch series 6 40mm case ( gps + cellular ) \n",
       " watch 6 , 4 : apple watch series 6 44 mm case ( gps + cellular ) \n",
       " watch 6 , 6 : apple watch series 7 41 mm case ( gps ) \n",
       " watch 6 , 7 : apple watch series 7 45 mm case ( gps ) \n",
       " watch 6 , 8 : apple watch series 7 41 mm case ( gps + cellular ) \n",
       " watch 6 , 9 : apple watch series 7 45 mm case ( gps + cellular ) \n",
       " watch 6 , 10 : apple watch se 40mm case ( gps ) \n",
       " watch 6 , 11 : apple watch se 44 mm case ( gps ) \n",
       " watch 6 , 12 : apple watch se 40mm case ( gps + cellular ) \n",
       " watch 6 , 13 : apple watch se 44 mm case ( gps + cellular ) \n",
       " watch 6 , 14 : apple watch series 8 41 mm case ( gps ) \n",
       " watch 6 , 15 : apple watch series 8 45 mm case ( gps ) \n",
       " watch 6 , 16 : apple watch series 8 41 mm case ( gps + cellular ) \n",
       " watch 6 , 17 : apple watch series 8 45 mm case ( gps + cellular ) \n",
       " watch 6 , 18 : apple watch ultra \n",
       " watch 7 , 1 : apple watch series 9 41 mm case ( gps ) \n",
       " watch 7 , 2 : apple watch series 9 45 mm case ( gps ) \n",
       " watch 7 , 3 : apple watch series 9 41 mm case ( gps + cellular ) \n",
       " watch 7 , 4 : apple watch series 9 45 mm case ( gps + cellular ) \n",
       " watch 7 , 5 : apple watch ultra 2 \n",
       " watch 7 , 8 : apple watch series 10 42 mm case ( gps ) \n",
       " watch 7 , 9 : apple watch series 10 46 mm case ( gps ) \n",
       " watch 7 , 10 : apple watch series 10 42 mm case ( gps + cellular ) \n",
       " watch 7 , 11 : apple watch series 10 46 mm case ( gps + cellular ) \n",
       " watch 7 , 12 : apple watch ultra 3 49 mm case \n",
       " watch 7 , 13 : apple watch se 3 40mm case \n",
       " watch 7 , 14 : apple watch se 3 44 mm case \n",
       " watch 7 , 15 : apple watch se 3 40mm case ( gps + cellular ) \n",
       " watch 7 , 16 : apple watch se 3 44 mm case ( gps + cellular ) \n",
       " watch 7 , 17 : apple watch series 11 42 mm case \n",
       " watch 7 , 18 : apple watch series 11 46 mm case \n",
       " watch 7 , 19 : apple watch series 11 42 mm case ( gps + celllular ) \n",
       " watch 7 , 20 : apple watch series 11 46 mm case ( gps + celllular ) \n",
       " audio accessory 1 , 1 : homepod \n",
       " 这 是 一封 自动 回复 邮件 。 您 的 来信 已 收到 ， 我会 尽快 回复 \n",
       " 这 是 来自 qq 邮箱 的 假期 自动 回复 邮件 。 * * * @ * * * . * * * 电话 ： 18311190877 \n",
       " thank you for maintaining this list . i was wondering if it should be the ipad pro 11-inch 3rd gen instead of the 5th gen ? \n",
       " https : / / the apple wiki . com / wiki / ipad _ pro _ ( 11 - inch ) _ ( 3 rd _ generation ) \n",
       " ipad 16 , 1 : ipad mini ( a 17 pro ) \n",
       " ipad 16 , 2 : ipad mini ( a 17 pro ) \n",
       " @ ioshc it has been discussed in past ( and not just once ) . there is no official naming from apple , so you can either take it as 3rd gen of ipad pro 11 \" or 5th gen of ipad pro ( regardles ds size ) , it 's up to interpretation . sometimes apple throws up some stupid pr ( like reusing old product names for new ones ) , some products even have gen , while others don ' t , for example latest model of ipad pro and ipad air doesn't have gen in name , they have m4 and m2 respectively , which again throws naming consitency into chaos . \n",
       " there are only 2 products that have continuous and understandable naming and thats watches ( disreganding 0 series ) , and iphone ( disregarding 2 g / 3 g / 3 gs ) . other products have no consistent or clear naming ( either it 's ipads , macs or macbooks ) . so there is 2 options , either use apple chaos , or create own naming scheme to help people distinguish between models . \n",
       " @ mex mer got it , thanks for you clarification , bro . \n",
       " @ adama wolf sorry if the question has already been asked but could you please consider adding apple tvs to this list ? i know it 's not a \" mobile \" device but i think it would make sense here . \n",
       " in any case , thanks for your work . \n",
       " sorry if the question has already been asked but could you please consider adding apple tvs to this list ? i know it 's not a \" mobile \" device but i think it would make sense here . \n",
       " for other device types , consider pinging the other mentioned repos & gists referenced in this gist . there are other sources to use . that way we keep this one purely for \" mobile \" . that and the fact that while very popular i can see , this gist shouldn't be the de facto standard for apple device mappings , there are others to choose from , and a repo version is a lot more desirable than a gist . \n",
       " fyi like half of the commercial names for the ipad ids are wrong , this needs to be corrected . \n",
       " 这 是 一封 自动 回复 邮件 。 您 的 来信 已 收到 ， 我会 尽快 回复 \n",
       " 这 是 来自 qq 邮箱 的 假期 自动 回复 邮件 。 * * * @ * * * . * * * 电话 ： 18311190877 \n",
       " apple watch series 10 ( hermes , china , 46 mm ) 希望 可以 继续 更新 apple watch 设备 信息 \n",
       " 这 是 一封 自动 回复 邮件 。 您 的 来信 已 收到 ， 我会 尽快 回复 \n",
       " 这 是 来自 qq 邮箱 的 假期 自动 回复 邮件 。 * * * @ * * * . * * * 电话 ： 18311190877 \n",
       " lte \n",
       " no watch 7 , 6 and watch 7 , 7 \n",
       " thanks @ yao yue and @ jarrod norwell added the watch and ipad mini models you pointed out . \n",
       " @ ob 0521 feel free to suggest edits and i 'll incorporate them if they make sense to me \n",
       " yet test logs reads my device as iphone 12 ? \n",
       " yet test logs reads my device as iphone 12 ? \n",
       " sound like issue with application you are using , that it doesn't properly map device name . \n",
       " identification here is correct . \n",
       " bellow is snippet from xcode device database \n",
       " \" iphone 1 , 1 \" : \" iphone \" , \n",
       " \" iphone 1 , 2 \" : \" iphone 3 g \" , \n",
       " \" iphone 2 , 1 \" : \" iphone 3 gs \" , \n",
       " \" iphone 3 , 1 \" : \" iphone 4 \" , \n",
       " \" iphone 3 , 2 \" : \" iphone 4 gsm rev a \" , \n",
       " \" iphone 3 , 3 \" : \" iphone 4 cdma \" , \n",
       " \" iphone 4 , 1 \" : \" iphone 4 s \" , \n",
       " \" iphone 5 , 1 \" : \" iphone 5 ( gsm ) \" , \n",
       " \" iphone 5 , 2 \" : \" iphone 5 ( gsm + cdma ) \" , \n",
       " \" iphone 5 , 3 \" : \" iphone 5c ( gsm ) \" , \n",
       " \" iphone 5 , 4 \" : \" iphone 5c ( global ) \" , \n",
       " \" iphone 6 , 1 \" : \" iphone 5s ( gsm ) \" , \n",
       " \" iphone 6 , 2 \" : \" iphone 5s ( global ) \" , \n",
       " \" iphone 7 , 1 \" : \" iphone 6 plus \" , \n",
       " \" iphone 7 , 2 \" : \" iphone 6 \" , \n",
       " \" iphone 8 , 1 \" : \" iphone 6 s \" , \n",
       " \" iphone 8 , 2 \" : \" iphone 6s plus \" , \n",
       " \" iphone 8 , 4 \" : \" iphone se ( gsm ) \" , \n",
       " \" iphone 9 , 1 \" : \" iphone 7 \" , \n",
       " \" iphone 9 , 2 \" : \" iphone 7 plus \" , \n",
       " \" iphone 9 , 3 \" : \" iphone 7 \" , \n",
       " \" iphone 9 , 4 \" : \" iphone 7 plus \" , \n",
       " \" iphone 10 , 1 \" : \" iphone 8 \" , \n",
       " \" iphone 10 , 2 \" : \" iphone 8 plus \" , \n",
       " \" iphone 10 , 3 \" : \" iphone x global \" , \n",
       " \" iphone 10 , 4 \" : \" iphone 8 \" , \n",
       " \" iphone 10 , 5 \" : \" iphone 8 plus \" , \n",
       " \" iphone 10 , 6 \" : \" iphone x gsm \" , \n",
       " \" iphone 11 , 2 \" : \" iphone xs \" , \n",
       " \" iphone 11 , 4 \" : \" iphone xs max \" , \n",
       " \" iphone 11 , 6 \" : \" iphone xs max global \" , \n",
       " \" iphone 11 , 8 \" : \" iphone xr \" , \n",
       " \" iphone 12 , 1 \" : \" iphone 11 \" , \n",
       " \" iphone 12 , 3 \" : \" iphone 11 pro \" , \n",
       " \" iphone 12 , 5 \" : \" iphone 11 pro max \" , \n",
       " \" iphone 12 , 8 \" : \" iphone se 2nd gen \" , \n",
       " \" iphone 13 , 1 \" : \" iphone 12 mini \" , \n",
       " \" iphone 13 , 2 \" : \" iphone 12 \" , \n",
       " \" iphone 13 , 3 \" : \" iphone 12 pro \" , \n",
       " \" iphone 13 , 4 \" : \" iphone 12 pro max \" , \n",
       " \" iphone 14 , 4 \" : \" iphone 13 mini \" , \n",
       " \" iphone 14 , 5 \" : \" iphone 13 \" , \n",
       " \" iphone 14 , 2 \" : \" iphone 13 pro \" , \n",
       " \" iphone 14 , 3 \" : \" iphone 13 pro max \" , \n",
       " \" iphone 14 , 6 \" : \" iphone se ( 3 rd gen ) \" , \n",
       " \" iphone 14 , 7 \" : \" iphone 14 \" , \n",
       " \" iphone 14 , 8 \" : \" iphone 14 plus \" , \n",
       " \" iphone 15 , 2 \" : \" iphone 14 pro \" , \n",
       " \" iphone 15 , 3 \" : \" iphone 14 pro max \" , \n",
       " \" iphone 15 , 4 \" : \" iphone 15 \" , \n",
       " \" iphone 15 , 5 \" : \" iphone 15 plus \" , \n",
       " \" iphone 16 , 1 \" : \" iphone 15 pro \" , \n",
       " \" iphone 16 , 2 \" : \" iphone 15 pro max \" , \n",
       " \" iphone 17 , 3 \" : \" iphone 16 \" , \n",
       " \" iphone 17 , 4 \" : \" iphone 16 plus \" , \n",
       " \" iphone 17 , 1 \" : \" iphone 16 pro \" , \n",
       " \" iphone 17 , 2 \" : \" iphone 16 pro max \" , \n",
       " the \" iphone 16 e \" is supported ？ \n",
       " the \" iphone 16 e \" is supported ？ \n",
       " couldn't find a reference to it , yet , despite an update available today . but \" enlightened \" guess and leaks from apple in the last few months would tend to give this : \n",
       " case \" iphone 17 , 5 \" : \n",
       " return \" iphone 16 e \" ; \n",
       " apple has not released new xcode since december , and it was not there . so we will need to wait for someone to buy device and connect it to computer . \n",
       " the \" iphone 16 e \" is supported ？ \n",
       " couldn't find a reference to it , yet , despite an update available today . but \" enlightened \" guess and leaks from apple in the last few months would tend to give this : \n",
       " case \" iphone 17 , 5 \" : \n",
       " return \" iphone 16 e \" ; \n",
       " yes , it 's quite possible , since it shares same cpu as iphone 16 , but i would hold with guesses , apple also might create hole ( as they sometimes do ) and mark it as iphone 17 , 6 \n",
       " ( * ￣ r ǒ ￣ ) so iphone 16e model value finally is what ？ \n",
       " i will buy one iphone 16e tomorrow 😄 \n",
       " hello please i need a iphone 16 pro max code source \n",
       " hello please i need a iphone 16 pro max code source \n",
       " 😄 haha \n",
       " it 's $ 599 in us , quite disapointing , since it 's 40 % hike up ( iphone se 2022 was selling for $ 429 ) , i would not say value is terrible , but definetly it doesn't fall to budget phone category . \n",
       " according to apple website , they will be available next friday ( eg . 28 . 2 . ) , but tomorow starts preorders . but if you get one , please post identification here . \n",
       " due to the needs of the company 's internal business , we need to maintain this mapping relationship for a long time . now put it on github , friends who need it can check it out \n",
       " [ apple - device - model ] \n",
       " iphone 16e is iphone 17 , 5 as confirmed in the xcode 16.3 beta ( device _ traits . db ) :\n",
       "\n",
       "---\n",
       "### 8. [Pipe Belling Machines, Socketing Machines Manufacturer and Exporter in Mumbai India](https://airopower.com/)\n",
       "*airopower.com*  \n",
       "**🌐 URL:** [https://airopower.com/](https://airopower.com/)\n",
       "\n",
       "**Snippet**\n",
       "> mail us at : airopower @ airopower . com \n",
       " ph no : + 91 9322294383 \n",
       " ph no : + 91 9821888985 \n",
       " one stop solution for polymer pipe industry pipe socketing , printing , testing , recycling \n",
       " welcome to ...\n",
       "\n",
       "**Summary**\n",
       "> mail us at : airopower @ airopower . com \n",
       " ph no : + 91 9322294383 \n",
       " ph no : + 91 9821888985 \n",
       " one stop solution for polymer pipe industry pipe socketing , printing , testing , recycling \n",
       " welcome to \n",
       " airopower systems \n",
       " airopower ® develops , manufactures and distributes end - to - end services – pre / post production ancillary equipment and quality control equipment for polymer pipe industries . founded in mumbai in 1988 as a deep nil consultant airopower has grown into worldwide , private limited enterprise & the family - run business , now in its second generation , has specialized in manufacturer , retailer , exporter of belling machine , socketing machine & many other equipment accessories of pvc pipe post production processes for the last number of decades . \n",
       " with a high production depth and experienced , qualified staff , airopower offers both standard machines as well as customized solutions . with an export share of over 35 % , airopower ® works internationally with over 25 countries with exclusive sales and service partners and has installed over 20,000 machines worldwide . \n",
       " our top products \n",
       " we at airopower systems envision to make our organisation one stop solution for polymer pipe industry by innovating and implementing best practices which makes our technical products , services best in india . \n",
       " training & service \n",
       " aside from high quality products , airopower ® offers its customers tailored solutions according to their respective needs . whether spare parts , dies or other accessories – airopower ® stands for comprehensive service and competent advice . \n",
       " at airopower ® we strive for constant interaction & cooperation with our customers and all our business associates , rather than being satisfied with short success & single sales , we aim for a long - term relationship . we supply machines and provide solutions that create genuine advantage and user benefit . \n",
       " constant interaction and close cooperation with all our clients , long - standing partners and frequent direct & virtual training programmes ensure that our associates are constantly up - to - date on our machines and new features technology . \n",
       " events \n",
       " 28 may \n",
       " 2017 \n",
       " plastindia 2012 installation \n",
       " one stop solution for polymer pipe industry by innovating and implementing best practices . . . \n",
       " 26 july \n",
       " 2017 \n",
       " airopower system \n",
       " one stop solution for polymer pipe industry by innovating and implementing best practices . . . \n",
       " 09 march \n",
       " 2018 \n",
       " airopower online laser \n",
       " one stop solution for polymer pipe industry by innovating and implementing best practices . . . \n",
       " get to know us \n",
       " who we are \n",
       " one stop solution for polymer pipe industry pre - production / post production / testing \n",
       " what we produce ? \n",
       " immense knowledge & in hand experience of working with most of reputed pipe industry . \n",
       " why us ? \n",
       " advance technology user - friendly machines with minimum maintenance .\n",
       "\n",
       "---\n",
       "### 9. [Sophos X-Ops: Advanced Threat Response Joint Task Force](https://www.sophos.com/en-us/x-ops)\n",
       "*sophos.com*  \n",
       "**🌐 URL:** [https://www.sophos.com/en-us/x-ops](https://www.sophos.com/en-us/x-ops)\n",
       "\n",
       "**Snippet**\n",
       "> sophos x - ops \n",
       " representing a significant advancement in cybersecurity , sophos x - ops is a joint task force of multiple specialized teams working together to address the complexities of modern cyb...\n",
       "\n",
       "**Summary**\n",
       "> sophos x - ops \n",
       " representing a significant advancement in cybersecurity , sophos x - ops is a joint task force of multiple specialized teams working together to address the complexities of modern cyber threats . \n",
       " our team \n",
       " sophos x - ops is a leading - edge cyber security initiative that unites more than 500 experts from various specialized security domains within sophos , including sophos labs , sophos artificial intelligence ( sophos ai ) , sophos mdr operations , sophos incident response , the field ciso team , x - ops threat intelligence , and the sophos internal security operations ( secops ) team . \n",
       " this cross - functional task force bolsters organizational defenses against increasingly sophisticated and dynamic cyber threats . \n",
       " by leveraging the combined expertise of its members , sophos x - ops offers a multidimensional response to cyberattacks , ensuring comprehensive protection , detection , and response capabilities . \n",
       " this collaborative and innovative approach ensures comprehensive threat mitigation and response , making sophos a leader in the cyber security landscape . \n",
       " this group works closely with the x - ops to teams develop original , high quality threat research , intelligence and findings for sharing with the broader security community . the team does this through ongoing collaboration , research and analysis across the teams and delivering these findings through the x - ops blog and social channels . \n",
       " preempt | advisory services \n",
       " sophos advisory services offers a comprehensive portfolio of cyber security testing , assessment , and incident readiness services . these services help organizations understand their security posture , identify weaknesses , and prepare for cyber attacks – ultimately reducing both organizational and reputational risk . by leveraging red , blue , and purple team exercises , as well as penetration testing , organizations can test their readiness for any attack . when an attack cannot be prevented , our cross - functional expertise enables us to deliver rapid investigation , analysis , and remediation with 24/7/365 incident response . the team delivering these services holds the highest accreditations globally , including cir enhanced ( uk ) , nsa cira ( formerly offered in the usa ) , bsi ( germany ) , and sss ( japan ) . \n",
       " protect | sophos labs \n",
       " this group is focused on providing proactive protection and detection solutions for the entire sophos product portfolio based on a deep understanding of the ever - evolving threat landscape . these solutions are available both in - product and in the cloud ( sophos labs intelix ) . sophos labs has been at the core of sophos products for over 25 years . \n",
       " predict | sophosai \n",
       " since 2017 , sophos has been elevating cyber security with ai . deep learning and genai capabilities are embedded in sophos products and delivered through the industry 's largest , most scalable , open ai platform . sophos labs and sophosai are mutually beneficial . sophos labs has a massive and ever - expanding database of categorized malicious code , executables , urls , etc . , from sophos products , services , and customer submissions worldwide . combine that unique training data with the ai skillset of the sophosai team , and you can see why the 50 + models used by sophos ' products and services provide robust and battle - proven protection . \n",
       " detect | mdr \n",
       " sophos mdr focuses on the customer and their environment , protecting them against advanced human - led attacks . as a flexible service with various tiers and response modes , sophos mdr can execute full - scale incident response or collaborate with the customer to manage security incidents with detailed threat notifications and guidance . the team provides proactive recommendations to improve security posture and performs root cause analysis to identify the underlying issues that led to an incident . in addition , they provide prescriptive guidance to address security weaknesses so attackers cannot exploit them in the future . visibility across a customer 's ecosystem is vital in detecting and responding to threats . sophos offers seamless integration with a broad , open ecosystem of technology partners , including endpoint , firewall , network , identity , email , backup and recovery , and other technologies . \n",
       " respond | incident response \n",
       " sophos incident response services respond to cyber attacks in progress or investigate a suspected breach . available to organizations large or small . the incident response team has seen and stopped it all , from ransomware and advanced persistent threats to insider threats and business email compromise , leveraging its expertise in forensic analysis and threat actor methodologies . \n",
       " when responding to an active threat , the time interval between the initial indicator of compromise and full threat mitigation must be as brief as possible . forensic investigations ensure a detailed understanding of how the attack unfolded , helping organizations address root causes and prevent recurrence . onboarding starts within hours , and most customers are triaged within 48 hours . \n",
       " sophos is accredited by the uk national cyber security centre ( ncsc ) as a level 2 certified incident response ( cir ) service provider and is qualified by the german federal office for information security as an advanced persistent threat ( apt ) response service provider . \n",
       " curate | counter threat unit \n",
       " the counter threat unit ( ctu ) is a team of cyber threat researchers and intelligence specialists focused on tracking , understanding , anticipating , and disrupting malicious activity . by analyzing threat actor behavior , monitoring hostile state actor espionage campaigns , tracking ecrime groups , drawing on real - world investigations and telemetry from across the sophos product lines the ctu identifies meaningful changes in adversary tradecraft and behaviour . our own intelligence picture is both validated and augmented by relationships with law enforcement and national cyber authorities . this threat intelligence , “ understanding of the threat ” , informs customers , the soc and sophos staff alike . inside x ops , this understanding , informs detection , prevention , and strategic decision - making . the ctu ’s work helps organizations stay ahead of evolving threats and strengthen their security posture . \n",
       " defend | ciso \n",
       " sophos ' mission is to protect customers from cyber attacks , the ciso teams contributes to this mission by defending sophos itself . \n",
       " attackers have long - tried to bypass security products . more recently security vendors and their products are directly targeted and used as entry points into organisations . the ciso teams mission is to prevent , detect and respond to these attacks . this mission requires us to defend our own infrastructure and services as well as products running directly in customer environments . this starts with threat - modelling and adherence to secure design principles , through assurance activities including code review , penetration testing , red teaming and bug bounties and , finally , product and infrastructure telemetry monitoring and instrumentation for effective detection and response . at sophos , we recognize that customer trust must be earned and verifiable . that 's why we have made transparency a longstanding cornerstone of our security program - ensuring customers can verify our commitment to security through open disclosure of threats , vulnerabilities , and details of our internal security practices on our trust center . \n",
       " inform | x - ops comms \n",
       " the x - ops comms team are skilled in taking the data and the research created by the sophos x - ops organizations and creating consumable content for people at all levels of understanding . from the in - depth technical discussion of how an attack unfolded to industry presentations and blog articles for the general public to thought leadership pieces explaining the themes and key messages from the data targeted at educating c-level staff and board members . \n",
       " guide | field ciso \n",
       " the team 's mission is to provide executive - level support in various areas of specialization , including regional , vertical , technological , and generalist . they aim to foster collaboration and drive innovation both within and beyond sophos . the field ciso team offers comprehensive support through public speaking , internal engagement , customer - executive collaboration , and in an advisory capacity . they also evangelize and adapt the sophos technology vision across all specializations and beyond , strengthening sophos ' market position and reputation . \n",
       " innovation in cyber security \n",
       " comprehensive threat understanding \n",
       " sophos x - ops provides detailed insights into how threats are constructed , delivered , and operated in real - time , allowing for a complete understanding of the attack landscape . this knowledge empowers sophos to develop robust and effective defenses against advanced threats . \n",
       " commitment to transparency \n",
       " sophos x - ops is dedicated to transparency and the open sharing of threat intelligence . the team regularly publishes threat research on its blog and participates in industry events and conferences to disseminate valuable information . this commitment helps businesses , governments , and individuals enhance their cyber security defenses . the team also collaborates with the industry through membership in organizations such as the cyber security and infrastructure security agency ( cisa ) joint cyber defense collaborative ( jcdc ) , microsoft active protections program ( mapp ) , and the cyber threat alliance ( cta ) . \n",
       " disruption and collaboration \n",
       " sophos x - ops disrupts cyber attackers by targeting their operations , infrastructure , and financial resources . this multidisciplinary approach involves collaborating with partners and law enforcement to neutralize threats effectively . the formal establishment of sophos x - ops enhances the speed and efficiency of these collaborative efforts , ensuring a swift response to fast - evolving cyber threats . \n",
       " innovation and future vision \n",
       " sophos x - ops fosters a strong foundation for innovation , which is essential for combating the rapid advancements in cybercrime . the integration of ai within the sophos security operations center ( soc ) enables the use of technology to anticipate security analysts ' needs and provide proactive defensive measures . the ai - assisted soc model is expected to accelerate security workflows and improve the detection and response to novel and critical threats . \n",
       " technology and threat intelligence from sophos x - ops are core to the protection functionality in every sophos product . learn more about sophos 's product offerings . \n",
       " sophos firewall \n",
       " sophos endpoint \n",
       " sophos email \n",
       " resources \n",
       " sophos x - ops brings together deep expertise across the attack environment to defend against even the most advanced threats . \n",
       " it takes two : the 2025 sophos active adversary report \n",
       " the dawn of our fifth year deepens our understanding of the enemies at the gate , and some tensions inside it ; plus , an anniversary gift from us to you . \n",
       " sophos threat report \n",
       " cyber threats to small businesses are expanding beyond ransomware . here ’s what you need to know . cybercrime affects people from all walks of life , but it hits small businesses the hardest . in the sophos 2024 threat report : cybercrime on main street , we take a close look at the expanding array of existential threats to smaller organizations . \n",
       " sophos pacific rim \n",
       " sophos defensive and counter - offensive operation with nation - state adversaries in china . \n",
       " advanced threat response joint task force \n",
       " cyber security threats are complex and sophisticated . \n",
       " sophos x - ops brings together deep expertise across the attack environment to defend against even the most advanced threats . \n",
       " deep malware analysis and response expertise from the sophos labs threat experts \n",
       " real - time intelligence from the sophos managed detection and response threat hunting and neutralizations specialists \n",
       " the frontline incident response experience of sophos emergency incident response \n",
       " world - leading deep learning capabilities from sophos ai \n",
       " security operations expertise from the team running sophos ’ own defenses \n",
       " deeper understanding drives better defenses \n",
       " sophos x - ops provides unparalleled insights into how threats are built , delivered , and operate in real time , revealing the full attack picture . armed with this deep understanding , sophos is able to build powerful , effective defenses against even the most advanced threats . \n",
       " sharing threat intelligence to enable defenders \n",
       " sophos is committed to transparency and openness with threat intelligence to enable businesses , governments , and individuals to better defend themselves from adversaries . sophos x - ops regularly publishes threat research on our blog and participates in conferences and industry events . \n",
       " resources \n",
       " sophos x - ops brings together deep expertise across the attack environment to defend against even the most advanced threats . \n",
       " active adversary multiple attackers report \n",
       " in recent months , we’ve noticed an uptick in the number of cases where organizations have been attacked multiple times . some attacks take place simultaneously ; others are separated by a few days , weeks , or months . some involve different kinds of malware , or double – even triple – infections of the same type . \n",
       " sophos 2024 threat report \n",
       " cyber threats to small businesses are expanding beyond ransomware . here ’s what you need to know . cybercrime affects people from all walks of life , but it hits small businesses the hardest . in the sophos 2024 threat report : cybercrime on main street , we take a close look at the expanding array of existential threats to smaller organizations . \n",
       " cyber threats : a 20-year retrospective \n",
       " in security we spend a lot of time trying to decipher the future . where ’s the next technology breakthrough ? what are cybercriminals going to do next ? \n",
       " an insider view into the increasingly complex king miner botnet \n",
       " king miner is an opportunistic botnet that keeps quiet and flies under the radar . the operators are ambitious and capable , but don’t have endless resources – they use any solution and concept that is freely available , getting inspiration from public domain tools as well as techniques used by apt groups . \n",
       " my kings : the slow but steady growth of a relentless botnet \n",
       " the botnet known as mykings wields a wide range of automated methods to break into servers – all just to install cryptocurrency miners . \n",
       " cloud snooper attack bypasses aws security measures \n",
       " an investigation into an attack against a cloud computing server reveals an unusual and innovative way for malware to communicate through amazon ’s firewalls\n",
       "\n",
       "---\n",
       "### 10. [myairops Flight - aircraft management SaaS solutions](https://myairops.com/products/flight-support/)\n",
       "*myairops.com*  \n",
       "**🌐 URL:** [https://myairops.com/products/flight-support/](https://myairops.com/products/flight-support/)\n",
       "\n",
       "**Snippet**\n",
       "> trip support and flight planning services \n",
       " using a blend of highly experienced people and next - generation software , we help operators maximize operational efficiencies and enhance overall customer...\n",
       "\n",
       "**Summary**\n",
       "> trip support and flight planning services \n",
       " using a blend of highly experienced people and next - generation software , we help operators maximize operational efficiencies and enhance overall customer experience . through the application of technology , alongside our highly skilled and train ed staff , we supply the services that put our customers at a significant advantage . \n",
       " trip planning and support \n",
       " when it comes to flight support , my air ops has the expertise to efficiently and reliably support you and maximize your operational performance . supporting over 11 , 400 flights per year , our extensive global experience makes us perfectly suited to provide completely tailored ser vices to ensure complete efficiency and cost - savings . our approach is different as we com bine a blend of our experienced team with our own underpinning technology which drives automation and intelligent decision - making . \n",
       " upon provision of our flight support services , we provide all of our customers with complete , transparent access to the systems we use , meaning you’ll have complete visibility and control over your software application . \n",
       " our trip planning and support services include : \n",
       " ground handling \n",
       " ground handling \n",
       " airport handling arrangements \n",
       " combining our extensive wealth of operations experience with our own advanced software system , my air ops flight , we have the knowledge to determine which handling agent / fbo to use to provide the best handling services down route at your destination airports . with agreements in place at various airports , we can sometimes receive discounts on handling fees which can be passed on to my air ops clients . not all handling agents provide the service level we would expect for our clients , from efficient communication to quality of services at each location , we look at all aspects of handling services to determine our preferred suppliers . \n",
       " slots / ppr \n",
       " slots in europe can be limited in peak seasons , requested slots versus what is allocated can create frustration amongst operators with tight schedules . what if you had the knowledge to hand of slot tolerances for each airport , so you knew what time you could take off either side of that slot to not bust a slot time and face a warning or worse , a fine from an airport ? with a large , experienced operations department team and a state - of - the - art operating system , my air ops trip support is the knowledge fountain perfect for an operator requiring that additional bit of information to create the perfect trip experience that puts less strain and stress on both passengers and operators . \n",
       " customs / immigration \n",
       " not all customs and immigration services are available for the same times an airport is open . through information stored in the my air ops system , along with a proactive attitude from our team , we verify we can operate a schedule based on if customs and immigration is available for a flight as well as checking an airport is open . time frames for supplying passenger and crew information to customs and immigration also varies around the world . we ensure our clients are aware of these time frames , so our clients are not penalised for late information supplied . \n",
       " flight planning \n",
       " flight planning \n",
       " we use your requirements to ensure all aspects of the plan meet your operational needs . we will arrange and plan for all alternatives , ensure airports are open and viable and make sure plans are filed and uploaded to your flight planning tool of choice . we will ensure flight levels are appropriately planned on the basis of fuel requirements and comfort . \n",
       " bring your own \n",
       " with a vastly experienced and adaptable operations department , my air ops trip support can use a wide range of flight planning software . if you have commitments with a flight planning software , then my air ops can use your account to take care of all aspects of flight planning and atc filling of your flight plans . \n",
       " my air ops foreflight \n",
       " using state of the art flight planning technology , my air ops trips support can provide a full flight planning package to support your trip requirements . we can add your aircraft to our database even for a one - off trip . foreflight software creates an excellent high level flight planning package with all the key and clear information required . \n",
       " operational support \n",
       " operational support \n",
       " ground transport \n",
       " using a large database built up over years of operating flights worldwide , my air ops trip support can provide crew and passenger transport that is safe , secure and trustworthy . \n",
       " catering \n",
       " turnaround times can be tight , so my air ops trip support can take care of your order and ensure catering is delivered fresh , tasty and on time . \n",
       " hotac \n",
       " arrive at your destination safe in the knowledge a comfortable bed awaits ! my air ops trip support can arrange hotel reservations around the globe for flight crew . \n",
       " security / risk assessment \n",
       " navigating the skies safely has never been more important or challenging , and my air ops trip support leverages industry leading providers to ensure your flight is the safest it can be , with comprehensive crew briefings and risk assessments available for more demanding destinations . \n",
       " permits \n",
       " permits \n",
       " charter permits \n",
       " with 40 years of commercial operator background , let my air ops navigate the increasingly complex global requirements for commercial charter permissions , so you don’t have to . \n",
       " overflight permits \n",
       " last minute trips often fall beneath the lead time for an overflight permission to be granted . forward thinking from the my air ops trip support team will look at alternative routes and obtain additional overflight permits should a permit not be approved before the flight is planned to take place , in order to prevent any risk of a schedule needing to be amended . \n",
       " landing permits \n",
       " knowing which countries require a landing permit depending on registration of an aircraft , type of operation , how many seats are on board an aircraft and how long it takes to obtain a landing permit are all valuable bits of information to know when planning a new trip schedule . my air ops trip support has all the information to hand to be able to and know when to obtain a permit correctly and efficiently . \n",
       " permit to fly \n",
       " have a technical fault with an aircraft but have approval for a one - off flight to fly to a maintenance facility ? all the paperwork and workload for that approval alone can be very stressful for an aircraft operator . having a trip support expert on hand to be able to relieve some of the pressure can be invaluable . when operating on a permit to fly , each country over flown requires notification of the flight and they must provide their approval for the flight to operate . with a rare extensive list of contacts within the my air ops department , this process can be accelerated . \n",
       " flight planning \n",
       " if you do not require the full-service offering provided by trip planning & support , we offer a focused flight planning only service offering . we can provide a service using your existing flight planning tools or we can provide a complete solution , along with our own software . we ’re completely flexible and are not limited to our own technology , we can work along side you with your existing technology solution . \n",
       " our process includes : \n",
       " our flight planning team pre - emptively produce a flight plan and the initial crew briefing pack from the earliest opportunity . this is key to ensuring efficient and timely response to customer changes . \n",
       " we begin by compiling operational restrictions , along with notams , destination alternatives and en - route alternatives to ensure your flight runs safely and efficiently . \n",
       " we coordinate handling requests and secure overflight and landing permits to ensure you have a safe and efficient flight . \n",
       " weather information will be analyzed by our highly trained team with the impact used to influence planning decisions . \n",
       " we compile required materials within the crew briefing pack and review and approve before transmission to the flight crew . \n",
       " the flight plan is filed , the relevant stc authorizes and the crew briefing pack is issued . \n",
       " inflight support \n",
       " we understand that plans can change when in flight . support needs to be provided in real - time 24 × 7 to assist the decision making process for diverts due to unexpected events like maintenance , weather or medical emergency . our inflight support team are there when you need us most . \n",
       " complete flexibility that suits you \n",
       " our trip support can be purchased in two ways : \n",
       " pay - as - you - go \n",
       " for those organizations that have an in-house capability , where an existing trip support arrangement is in place or where customers want the flexibility to have no standing commitment . \n",
       " this option allows our “ go now ” feature , simply call or email your request and we will do the rest . organizing all aspects of the trip , filing all flight plans and providing all briefing materials . \n",
       " scenarios include organizations who wish to access our specialist skilled services arranging your trip within europe , middle east and africa . whilst we offer full global coverage , many organizations access us for our specialist knowledge and expert skills within this region . \n",
       " annual commitment \n",
       " the annual commitment model is suited for organizations who want to outsource trip support to us over a longer term . this offers preferential pricing over the pay - as - you - go model . \n",
       " a monthly fee covers all trips you may have on a per aircraft basis ; no matter how many trips that may be . \n",
       " we provide simple transparent pricing so there are no hidden fees or surprises . as with all our service delivery models we have an agreed price list for permits that we publish to you in advance so you always know what you can expect to pay . any services we arrange or purchase on your behalf are passed through with no additional mark - up added . if you have an existing flight planning tool that you want us to use then we can use this preference or provide you services using our existing tools and capabilities . if you want the flexibility of integrating our team into the task workflow of your existing flight scheduling software , just contact us and we would be happy to help . \n",
       " download our flight support service guide by filling out the form below\n"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "client = LangSearchClient(api_key=Config.API_KEY, db_path=Config.DB_PATH)\n",
    "results = client.search(\"https://www.airops.com/\")\n",
    "client.display_results(\"https://www.airops.com/\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86008291",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
